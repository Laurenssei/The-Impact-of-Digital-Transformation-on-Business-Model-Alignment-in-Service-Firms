
---
title: >
  The Impact of Digital Transformation on Business Mod, ...,.
author: 
  - name: "Laurens"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
abstract: |
  This  study investigates the relationships between digital transformation (DT), business model alignment (BMA), financial health (FH), and customer demand (CD). Uding  survey data from 235 respondents. The study addresses three research questions: the impact of DT on BMA, the moderating role of FH on the DT-BMA relationship, and the mediating effect of CD on the DT-BMA link. Using regression analysis, moderation and mediation models, structural equation modeling (SEM), and qualitative thematic analysis of open-ended responses, the findings reveal a strong positive direct effect of DT on BMA (β = 0.82, R² = 0.736, p < 0.001), supporting Hypothesis H1. FH shows a significant direct effect (β = 0.44, p < 0.001) but mixed moderation (non-significant in base model, p = 0.10; significant in full model, β = -0.19, p = 0.02), partially supporting H2. CD partially mediates the DT-BMA relationship (indirect effect = 0.113, 13.7% of total effect, p = 0.001), supporting H3. Qualitative insights highlight benefits like efficiency and customer experience, challenges such as costs and resistance to change, and recommendations for training and strategic planning. Industry variations show consulting firms leading in DT and BMA adoption. The integrated model (R² = 0.78) provides the best fit, though SEM fit indices suggest model refinement. Implications emphasize leveraging DT for business innovation, supported by FH and responsive to CD, with recommendations for policy and practice in service sectors.
  
keywords:
output:
  html_document:
    theme: cosmo
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: true
    number_sections: true
    code_folding: hide
    fig_caption: true
    df_print: paged
    highlight: pygments
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 3
    number_sections: true
    fig_caption: true
    keep_tex: false
  word_document:
    toc: true
    toc_depth: 3
    fig_caption: true
    reference_docx: "template.docx"
link-citations: true
params:
  show_code: 
    label: "Show code chunks"
    value: false
    input: checkbox
  analysis_date: !r Sys.Date()
  data_path: "data/"
  output_path: "outputs/"
  seed: 42
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
# Suppress messages and warnings from library loads
suppressPackageStartupMessages({
  library(psych)
  library(car)
  library(corrplot)
  library(broom)
  library(biotools)    # For Box's M test
  library(ResourceSelection)
  library(rstatix)      # kruskal_test, dunn_test
library(viridis)
  library(lme4)    # For mixed-effects modeling
  library(randomForest)
  library(rcompanion)
library(knitr)
  library(effects)
  library(effectsize)
library(sjPlot)
  library(MASS)
   library(tidyverse)
  library(ggplot2)
library(janitor)
library(forcats)
library(scales)
library(vcd)
library(knitr)
library(kableExtra)
library(gtsummary)  # For publication-ready tables
library(corrplot)   # For correlation heatmaps
library(ggpubr)     # For advanced ggplot2 extensions
library(gridExtra)  # For arranging multiple plots
library(broom)
# Load necessary libraries
library(dplyr)
library(ggplot2)
  library(readxl)
  library(janitor)
  library(skimr)
  library(moments)
  library(knitr)
  library(kableExtra)
  library(gtsummary)
  library(gt)
  library(DataExplorer)
  library(GGally)
  library(plotly)
  library(patchwork)
  library(corrplot)
  library(scales)
 library(likert)
  library(ggpubr)
})

# Global chunk options
knitr::opts_chunk$set(
  echo = params$show_code,
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  fig.width = 10,
  fig.height = 6,
  out.width = "95%",
  dpi = 300
)

# Custom table rendering function
create_table <- function(data, caption = "") {
  data %>%
    kable(caption = caption, align = "l") %>%
    kable_styling(
      bootstrap_options = c("striped", "hover", "condensed"),
      full_width = FALSE,
      position = "center"
    ) %>%
    scroll_box(width = "100%", height = "400px")
}

# Metadata for document
doc_info <- list(
  title = rmarkdown::metadata$title,
  author = rmarkdown::metadata$author,
  generated_on = format(params$analysis_date, "%B %d, %Y"),
  version = "v1.2",
  r_version = paste(R.version$major, R.version$minor, sep = "."),
  packages = sessionInfo()$otherPkgs
)



# Custom theme for publication-ready plots
theme_publication <- function(base_size = 11,
                             base_family = "",
                             grid_color = "grey94",
                             border_color = "grey30",
                             background_color = "white",
                             text_color = "grey15",
                             subtitle_color = "grey40",
                             caption_color = "grey50",
                             legend_position = "right") {
  
  # Validate inputs
  legend_position <- match.arg(legend_position, c("right", "left", "top", "bottom", "none"))
  
  # Calculate relative sizes for consistent scaling
  title_size <- base_size + 3
  subtitle_size <- base_size + 1
  caption_size <- base_size - 1
  axis_title_size <- base_size + 0.5
  axis_text_size <- base_size - 0.5
  legend_title_size <- base_size
  legend_text_size <- base_size - 1
  strip_text_size <- base_size
  
  # Base theme
  base_theme <- theme_minimal(base_size = base_size, base_family = base_family)
  
  # Build publication theme
  base_theme +
    theme(
      # Plot elements - centered for publications
      plot.title = element_text(
        size = title_size,
        face = "bold",
        hjust = 0.5,  # Centered for publications
        color = text_color,
        margin = margin(b = 15)
      ),
      plot.subtitle = element_text(
        size = subtitle_size,
        hjust = 0.5,  # Centered for publications
        color = subtitle_color,
        margin = margin(b = 20),
        lineheight = 1.1
      ),
      plot.caption = element_text(
        size = caption_size,
        face = "italic",
        hjust = 0,  # Left-aligned for source citations
        color = caption_color,
        margin = margin(t = 15)
      ),
      plot.title.position = "plot",  # Align with plot area, not panel
      plot.caption.position = "plot",
      
      # Axis elements
      axis.title = element_text(
        size = axis_title_size,
        face = "bold",
        color = text_color
      ),
      axis.title.x = element_text(margin = margin(t = 10)),
      axis.title.y = element_text(margin = margin(r = 10), angle = 90),
      axis.text = element_text(
        size = axis_text_size,
        color = text_color
      ),
      axis.text.x = element_text(margin = margin(t = 5)),
      axis.text.y = element_text(margin = margin(r = 5)),
      
      # Axis lines and ticks
      axis.line = element_line(color = border_color, linewidth = 0.5),
      axis.ticks = element_line(color = border_color, linewidth = 0.3),
      axis.ticks.length = unit(0.15, "cm"),
      
      # Legend elements
      legend.title = element_text(
        size = legend_title_size,
        face = "bold",
        color = text_color
      ),
      legend.text = element_text(
        size = legend_text_size,
        color = text_color
      ),
      legend.position = legend_position,
      legend.key.size = unit(0.8, "cm"),
      legend.margin = margin(10, 10, 10, 15),
      legend.box.spacing = unit(0.4, "cm"),
      legend.background = element_rect(
        fill = background_color,
        color = NA
      ),
      legend.key = element_rect(
        fill = background_color,
        color = NA
      ),
      
      # Panel elements - clean grid for publications
      panel.grid.major = element_line(
        color = grid_color,
        linewidth = 0.3,
        linetype = "solid"
      ),
      panel.grid.minor = element_blank(),  # Remove minor grid for cleaner look
      panel.border = element_rect(
        color = border_color,
        fill = NA,
        linewidth = 0.5
      ),
      panel.background = element_rect(
        fill = background_color,
        color = NA
      ),
      
      # Facet strip elements
      strip.background = element_rect(
        fill = "grey96",
        color = border_color,
        linewidth = 0.3
      ),
      strip.text = element_text(
        size = strip_text_size,
        face = "bold",
        color = text_color,
        margin = margin(4, 8, 4, 8)
      ),
      strip.placement = "outside",
      
      # Plot background and margins
      plot.background = element_rect(
        fill = background_color,
        color = NA
      ),
      plot.margin = margin(20, 20, 20, 20),
      
      # Ensure complete theme
      complete = TRUE
    )
}

# Variant themes for specific publication needs

#' Black and white theme for print publications
theme_publication_bw <- function(...) {
  theme_publication(
    grid_color = "grey90",
    border_color = "black",
    text_color = "black",
    subtitle_color = "grey30",
    caption_color = "grey40",
    ...
  )
}

#' Minimal theme for simple, clean plots
theme_publication_minimal <- function(...) {
  theme_publication(
    grid_color = "grey96",
    ...
  ) +
    theme(
      panel.border = element_blank(),
      axis.line = element_line(color = "grey40", linewidth = 0.4),
      panel.grid.major = element_line(color = "grey96", linewidth = 0.25)
    )
}

#' Presentation theme with larger text
theme_publication_presentation <- function(...) {
  theme_publication(
    base_size = 14,  # Larger text for presentations
    grid_color = "grey92",
    ...
  )
}

#' Times New Roman theme for academic journals
theme_publication_times <- function(...) {
  theme_publication(
    base_family = "Times New Roman",
    base_size = 10,  # Smaller size for academic publications
    ...
  )
}


# # Set as default theme
 theme_set(theme_publication())

```











```{r}

# Load required libraries
library(readxl)
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(corrplot)
library(ggcorrplot)
library(psych)
library(lavaan)
library(semPlot)
library(car)
library(lmtest)
library(moments)
library(Hmisc)
library(janitor)
library(viridis)
library(RColorBrewer)
library(gridExtra)
library(plotly)
library(DT)



# Custom kable function
kk <- function(df, caption = NULL, digits = 2){
  kable(df, caption = caption, digits = digits, align = "l") |>
    kable_classic(full_width = FALSE, html_font = "Cambria") |>
    kable_styling(font_size = 12, bootstrap_options = c("striped", "hover"))
}
```




## Research Framework

**Research Objectives:**
1. Examine the relationship between digital transformation and service business models

2. Assess the moderating role of financial health on the DT-BMA relationship  

3. Investigate the effect of customer demand on the DT-BMA relationship

**Research Questions:**
1. RQ1: What are the impacts of digital transformation on service business models?

2. RQ2: What is the moderating role of financial health in the relationship between digital transformation and service business models?

3. RQ3: How does customer demand affect the relationship between digital transformation and business models?

```{r}

# Load required libraries
library(dplyr)
library(readxl)
library(janitor)
library(psych)
library(ggplot2)
library(knitr)
library(kableExtra)
library(lm.beta)
library(car)
library(mediation)
library(moments)
library(corrplot)
library(lavaan)
library(semPlot)
library(Hmisc)
library(VIM)
library(mice)
library(lmtest)
library(sandwich)


# Custom kable function
kk <- function(df, caption = NULL, digits = 2){
  kable(df, caption = caption, digits = digits, align = "l") |>
    kable_classic(full_width = FALSE, html_font = "Cambria") |>
    kable_styling(font_size = 12, bootstrap_options = c("striped", "hover"))
}

# Load and prepare data
digital_df <- read_excel("Downloads/Digital transformation 3.xlsx") %>% 
  clean_names() %>%
  rename(
    # Demographics
    gender = sex,
    age_group = x2_age_group,
    education = x3_highest_educational_qualification,
    position = x4_position_in_the_firm,
    firm_type = x5_type_of_service_based_firm,
    
    # Digital Transformation variables
    dt_leadership_support = digital_transformation_our_leadership_actively_promotes_digital_initiatives_our_leadership_actively_promotes_digital_initiatives,
    dt_investment_consistency = digital_transformation_there_is_consistent_investment_in_digital_tools_and_systems,
    dt_process_integration = digital_transformation_digital_transformation_is_integrated_into_all_core_business_processes,
    dt_staff_training = digital_transformation_our_staff_have_access_to_adequate_digital_training_resources,
    dt_automation_productivity = digital_transformation_automation_is_improving_productivity_in_our_organization,
    dt_analytical_tools = digital_transformation_we_use_analytical_tools_to_support_decisions,
    dt_it_infrastructure = digital_transformation_it_infrastructure_supports_the_digital_needs_of_the_firm,
    
    # Business Model Alignment variables
    bma_digital_revenue = business_model_alignment_our_revenue_model_includes_digital_products_or_services,
    bma_digital_channels = business_model_alignment_we_have_adopted_new_digital_channels_for_delivering_services,
    bma_customer_satisfaction = business_model_alignment_business_model_changes_have_improved_customer_satisfaction,
    bma_platform_models = business_model_alignment_we_have_adopted_platform_based_or_subscription_models,
    bma_feedback_loops = business_model_alignment_we_use_digital_feedback_loops_to_improve_offerings,
    bma_collaboration = business_model_alignment_internal_collaboration_has_improved_through_digital_tools,
    bma_competitive_advantage = business_model_alignment_our_competitive_advantage_depends_on_digital_innovation,
    
    # Financial Health variables
    fh_project_capability = financial_health_the_organization_is_financially_capable_of_supporting_digital_projects,
    fh_roi_tracking = financial_health_we_regularly_track_roi_on_digital_investments,
    fh_liquidity_ratios = financial_health_our_firm_maintains_healthy_liquidity_ratios,
    fh_constraints_delay = financial_health_financial_constraints_delay_tech_adoption,
    fh_longterm_evaluation = financial_health_we_evaluate_digital_tools_based_on_long_term_financial_performance,
    fh_cost_reduction = financial_health_digital_transformation_has_helped_reduce_operational_costs,
    
    # Customer Demand variables
    cd_response_speed = customer_demand_we_respond_quickly_to_changing_customer_demands,
    cd_platform_preference = customer_demand_customers_prefer_using_mobile_or_digital_platforms_for_service_access,
    cd_personalization = customer_demand_personalized_digital_services_are_important_to_our_customers,
    cd_behavior_analysis = customer_demand_we_regularly_analyze_customer_digital_behavior_and_feedback,
    cd_strategy_influence = customer_demand_customer_expectations_influence_our_digital_strategy,
    cd_omnichannel_demand = customer_demand_there_is_increasing_demand_for_omnichannel_experiences,
    cd_speed_convenience = customer_demand_customers_value_speed_and_convenience_from_digital_services,
    cd_adoption_improvement = customer_demand_customer_digital_adoption_has_improved_in_recent_years,    # Open-ended questions
    benefits_top3 = in_your_view_what_are_the_top_3_benefits_of_digital_transformation_in_your_organization,
    challenges_key = what_are_the_key_challenges_your_organization_has_faced_in_implementing_digital_tools,
    recommendations = what_recommendations_would_you_suggest_to_improve_the_digital_transformation_process
  ) %>%
  mutate(
    # Reverse code negative item
    fh_constraints_delay_rev = 6 - fh_constraints_delay,
    
    # Composite scores
    DT_score = (dt_leadership_support + dt_investment_consistency + 
                dt_process_integration + dt_staff_training + 
                dt_automation_productivity + dt_analytical_tools + 
                dt_it_infrastructure) / 7,
    
    BMA_score = (bma_digital_revenue + bma_digital_channels + 
                 bma_customer_satisfaction + bma_platform_models + 
                 bma_feedback_loops + bma_collaboration + 
                 bma_competitive_advantage) / 7,
    
    FH_score = (fh_project_capability + fh_roi_tracking + 
                fh_liquidity_ratios + fh_constraints_delay_rev + 
                fh_longterm_evaluation + fh_cost_reduction) / 6,
    
    CD_score = (cd_response_speed + cd_platform_preference + 
                cd_personalization + cd_behavior_analysis + 
                cd_strategy_influence + cd_omnichannel_demand + 
                cd_speed_convenience + cd_adoption_improvement) / 8,
    
    # Centered variables for interaction analysis
    DT_centered = scale(DT_score, scale = FALSE)[,1],
    FH_centered = scale(FH_score, scale = FALSE)[,1],
    CD_centered = scale(CD_score, scale = FALSE)[,1]
  )


```



# Introduction



The study investigates the impact of digital transformation on service business models (RQ1), the moderating role of financial health (RQ2), and the mediating role of customer demand (RQ3). The dataset includes responses from 235 participants across service-based firms, with demographic details, Likert-scale items for four constructs (DT, BMA, FH, CD), and open-ended responses on benefits, challenges, and recommendations. 



# Demographic Analysis

## demographic Characteristics


This section presents the demographic characteristics of the sample (N=235) across gender, age group, education, position, and firm type. These characteristics provide context for the study .

The following tables summarize the distribution of demographic variables, including counts and percentages


```{r demographic_analysis}
# Gender distribution
gender_dist <- digital_df %>%
  count(gender) %>%
  mutate(percentage = round(n/sum(n)*100, 1)) %>%
  arrange(desc(n))

# Age group distribution
age_dist <- digital_df %>%
  count(age_group) %>%
  mutate(percentage = round(n/sum(n)*100, 1)) %>%
  arrange(desc(n))

# Education distribution
edu_dist <- digital_df %>%
  count(education) %>%
  mutate(percentage = round(n/sum(n)*100, 1)) %>%
  arrange(desc(n))

# Position distribution
pos_dist <- digital_df %>%
  count(position) %>%
  mutate(percentage = round(n/sum(n)*100, 1)) %>%
  arrange(desc(n))

# Firm type distribution
firm_dist <- digital_df %>%
  count(firm_type) %>%
  mutate(percentage = round(n/sum(n)*100, 1)) %>%
  arrange(desc(n))

# Display tables
kk(gender_dist, "Gender Distribution of Respondents")
kk(age_dist, "Age Group Distribution")
kk(edu_dist, "Educational Background Distribution")
kk(pos_dist, "Position Distribution")
kk(firm_dist, "Firm Type Distribution")
```


```{r}
# Create demographic plots
 ggplot(gender_dist, aes(x = reorder(gender, n), y = n, fill = gender)) +
  geom_col(alpha = 0.8, width = 0.6) +
  geom_text(aes(label = paste0( "\n", percentage, "%")), 
            hjust = -0.1, size = 4, fontface = "bold") +
  scale_fill_viridis_d(option = "plasma", begin = 0.3, end = 0.8) +
  coord_flip() +
  labs(title = "Gender Distribution", x = "Gender", y = "Count") +
  theme(legend.position = "none")

ggplot(age_dist, aes(x = reorder(age_group, n), y = n, fill = age_group)) +
  geom_col(alpha = 0.8) +
  geom_text(aes(label = paste0( "\n", percentage, "%")), 
            hjust = -0.1, size = 3.5, fontface = "bold") +
  scale_fill_brewer(type = "qual", palette = "Set1") +
  coord_flip() +
  labs(title = "Age Group Distribution", x = "Age Group", y = "Count") +
  theme(legend.position = "none")

ggplot(edu_dist, aes(x = reorder(education, n), y = n, fill = education)) +
  geom_col(alpha = 0.8) +
  geom_text(aes(label = paste0(percentage, "%")), 
            hjust = -0.1, size = 3.5, fontface = "bold") +
  scale_fill_brewer(type = "qual", palette = "Set1") +
  coord_flip() +
  labs(title = "Educational Background", x = "Education Level", y = "Count") +
  theme(legend.position = "none")

 ggplot(firm_dist, aes(x = reorder(firm_type, n), y = n, fill = firm_type)) +
  geom_col(alpha = 0.8) +
  geom_text(aes(label = paste0(percentage, "%")), 
            hjust = -0.1, size = 3.5, fontface = "bold") +
  scale_fill_viridis_d(option = "turbo", begin = 0.1, end = 0.9) +
  coord_flip() +
  labs(title = "Firm Type Distribution", x = "Firm Type", y = "Count") +
  theme(legend.position = "none")


```



Gender: 55.7% male (n = 131), 44.3% female (n = 104).

Age: Predominantly younger respondents, with 35.3% aged 25–34 years (n = 83) and 25.1% aged 18–24 years (n = 59). Older groups (45–54: 10.6%, 55+: 6.0%) were less represented.

Education: Most respondents held a Bachelor’s degree (47.7%, n = 112) or Master’s degree (26.4%, n = 62), followed by Diploma/HND (12.3%), PhD (8.9%), and Senior High School (4.7%).

Position: Technical/IT staff (30.2%, n = 71), middle managers (24.3%, n = 57), and administrative staff (23.0%, n = 54) were the most common roles. Senior managers (16.6%) and others (e.g., students, academics) were less frequent.

Firm Type: Consulting/Professional Services (27.2%, n = 64), Financial Services (23.4%, n = 55), and Education/Training (21.3%, n = 50) dominated, followed by Hospitality & Tourism (16.2%) and Healthcare (11.9%).


Observations:The sample is diverse in gender, education, and firm type but skewed toward younger respondents and certain roles (e.g., Technical/IT)







# Measurement Model Assessment

###  Reliability Analysis

This section assesses the reliability and validity of the constructs used in the study: Digital Transformation (DT), Business Model Alignment (BMA), Financial Health (FH), and Customer Demand (CD). Reliability is evaluated using Cronbach’s alpha, with values ≥ 0.7 considered acceptable, ≥ 0.8 good, and ≥ 0.9 excellent. Validity is assessed using composite reliability (CR, ≥ 0.7 acceptable) and average variance extracted (AVE, ≥ 0.5 for convergent validity). These analyses ensure robust measurement of constructs critical to the research objectives . 



```{r}
library(dplyr)
library(psych)
library(tibble)

# Digital Transformation reliability (exclude DT_score and DT_centered)
dt_items <- digital_df %>%
  select(starts_with("dt_")) %>%
  select(-ends_with("_score"), -ends_with("_centered"))
dt_alpha <- psych::alpha(dt_items, check.keys = TRUE)


# Repeat for others
bma_items <- digital_df %>%
  select(starts_with("bma_")) %>%
  select(-ends_with("_score"), -ends_with("_centered"))
bma_alpha <- psych::alpha(bma_items, check.keys = TRUE)

fh_items <- digital_df %>%
  select(starts_with("fh_")) %>%
  select(-ends_with("_score"), -ends_with("_centered"))
fh_alpha <- psych::alpha(fh_items, check.keys = TRUE)


cd_items <- digital_df %>%
  select(starts_with("cd_")) %>%
  select(-ends_with("_score"), -ends_with("_centered"))
cd_alpha <- psych::alpha(cd_items, check.keys = TRUE)


# Reliability summary table
alphas <- c(dt_alpha$total$std.alpha, bma_alpha$total$std.alpha, 
            fh_alpha$total$std.alpha, cd_alpha$total$std.alpha)

reliability_results <- tibble(
  Construct = c("Digital Transformation", "Business Model Alignment", 
                "Financial Health", "Customer Demand"),
  Items = c(ncol(dt_items), ncol(bma_items), ncol(fh_items), ncol(cd_items)),
  Cronbach_Alpha = round(alphas, 3),
  Interpretation = case_when(
    alphas >= 0.9 ~ "Excellent",
    alphas >= 0.8 ~ "Good",
    alphas >= 0.7 ~ "Acceptable",
    TRUE ~ "Poor"
  )
)

kk(reliability_results, "Cronbach's Alpha Reliability Analysis")

```

Cronbach’s Alpha

All constructs demonstrate high internal consistency, with α ≥ 0.89, ensuring reliable measurement.



###  Validity Assessment

```{r validity_analysis}
# Factor analysis for each construct
dt_fa <- fa(dt_items, nfactors = 1, rotate = "none", fm = "minres")
bma_fa <- fa(bma_items, nfactors = 1, rotate = "none", fm = "minres")
fh_fa <- fa(fh_items, nfactors = 1, rotate = "none", fm = "minres")
cd_fa <- fa(cd_items, nfactors = 1, rotate = "none", fm = "minres")

# Extract loadings and calculate composite reliability and AVE
calc_cr_ave <- function(loadings) {
  loadings <- as.numeric(loadings)
  loadings <- loadings[!is.na(loadings)]
  sum_loadings_sq <- sum(loadings^2)
  sum_loadings <- sum(abs(loadings))
  
  # Composite Reliability
  cr <- (sum_loadings^2) / ((sum_loadings^2) + sum(1 - loadings^2))
  
  # Average Variance Extracted
  ave <- sum_loadings_sq / length(loadings)
  
  return(list(CR = cr, AVE = ave))
}

dt_validity <- calc_cr_ave(dt_fa$loadings[,1])
bma_validity <- calc_cr_ave(bma_fa$loadings[,1])
fh_validity <- calc_cr_ave(fh_fa$loadings[,1])
cd_validity <- calc_cr_ave(cd_fa$loadings[,1])

validity_results <- data.frame(
  Construct = c("Digital Transformation", "Business Model Alignment", "Financial Health", "Customer Demand"),
  Composite_Reliability = round(c(dt_validity$CR, bma_validity$CR, fh_validity$CR, cd_validity$CR), 3),
  AVE = round(c(dt_validity$AVE, bma_validity$AVE, fh_validity$AVE, cd_validity$AVE), 3),
  Convergent_Validity = ifelse(c(dt_validity$AVE, bma_validity$AVE, fh_validity$AVE, cd_validity$AVE) >= 0.5, 
                               "Established", "Questionable"),
  Factor_Loadings_Range = c(
    paste(round(min(dt_fa$loadings[,1]), 2), "-", round(max(dt_fa$loadings[,1]), 2)),
    paste(round(min(bma_fa$loadings[,1]), 2), "-", round(max(bma_fa$loadings[,1]), 2)),
    paste(round(min(fh_fa$loadings[,1]), 2), "-", round(max(fh_fa$loadings[,1]), 2)),
    paste(round(min(cd_fa$loadings[,1]), 2), "-", round(max(cd_fa$loadings[,1]), 2))
  )
)

kk(validity_results, "Convergent Validity Analysis")


# Discriminant validity - HTMT ratios
cor_constructs <- cor(digital_df[, c("DT_score", "BMA_score", "FH_score", "CD_score")], use = "complete.obs")

# Calculate HTMT manually
calc_htmt <- function(items1, items2) {
  inter_construct_cor <- cor(items1, items2, use = "complete.obs")
  avg_inter <- mean(abs(inter_construct_cor))
  
  intra_cor1 <- cor(items1, use = "complete.obs")
  intra_cor2 <- cor(items2, use = "complete.obs")
  
  avg_intra1 <- mean(abs(intra_cor1[upper.tri(intra_cor1)]))
  avg_intra2 <- mean(abs(intra_cor2[upper.tri(intra_cor2)]))
  
  htmt <- avg_inter / sqrt(avg_intra1 * avg_intra2)
  return(htmt)
}

htmt_results <- data.frame(
  Construct_Pair = c("DT-BMA", "DT-FH", "DT-CD", "BMA-FH", "BMA-CD", "FH-CD"),
  HTMT_Ratio = round(c(
    calc_htmt(dt_items, bma_items),
    calc_htmt(dt_items, fh_items), 
    calc_htmt(dt_items, cd_items),
    calc_htmt(bma_items, fh_items),
    calc_htmt(bma_items, cd_items),
    calc_htmt(fh_items, cd_items)
  ), 3)
)

kk(htmt_results, "Discriminant Validity (HTMT Ratios)")
```


Composite Reliability (CR): All constructs have CR ≥ 0.89 (DT: 0.91, BMA: 0.89, FH: 0.92, CD: 0.91), indicating strong reliability.

Average Variance Extracted (AVE): All constructs meet the threshold for convergent validity (AVE ≥ 0.5):



HTMT Ratios: All construct pairs exceed the recommended threshold of 0.85, suggesting potential issues with discriminant validity:


High HTMT ratios indicate that constructs may not be sufficiently distinct, particularly DT and BMA, which may share conceptual overlap.




# Descriptive Statistics




##  Descriptive Analysis

```{r descriptive_analysis}

library(dplyr)
library(tidyr)
library(moments) # skewness, kurtosis

desc_stats <- digital_df %>%
  select(DT_score, BMA_score, FH_score, CD_score) %>%
  summarise(across(
    everything(),
    list(
      N        = ~sum(!is.na(.)),
      Mean     = ~round(mean(., na.rm = TRUE), 3),
      SD       = ~round(sd(., na.rm = TRUE), 3),
      Median   = ~round(median(., na.rm = TRUE), 3),
      Min      = ~round(min(., na.rm = TRUE), 3),
      Max      = ~round(max(., na.rm = TRUE), 3),
      Skewness = ~round(skewness(., na.rm = TRUE), 3),
      Kurtosis = ~round(kurtosis(., na.rm = TRUE), 3)
    ),
    .names = "{.col}_{.fn}"
  )) %>%
  pivot_longer(
    everything(),
    names_to = c("Variable", "Statistic"),
    names_sep = "_(?=[^_]+$)"   # split at last underscore
  ) %>%
  pivot_wider(names_from = Statistic, values_from = value) %>%
  mutate(Variable = case_when(
    Variable == "DT_score"  ~ "Digital Transformation",
    Variable == "BMA_score" ~ "Business Model Alignment",
    Variable == "FH_score"  ~ "Financial Health",
    Variable == "CD_score"  ~ "Customer Demand",
    TRUE ~ Variable
  )) %>%
  select(Variable, N, Mean, SD, Median, Min, Max, Skewness, Kurtosis) # tidy order




kk(desc_stats, "Descriptive Statistics for Main Constructs")

# Individual item descriptive statistics for each construct
# Digital Transformation individual items
dt_individual <- digital_df %>%
  select(starts_with("dt_")) %>%
  select(-ends_with("_score"), -ends_with("_centered")) %>%   # exclude composite
  summarise_all(list(
    Mean     = ~round(mean(., na.rm = TRUE), 3),
    SD       = ~round(sd(., na.rm = TRUE), 3),
    Skewness = ~round(skewness(., na.rm = TRUE), 3),
    Kurtosis = ~round(kurtosis(., na.rm = TRUE), 3)
  )) %>%
  gather(key = "Metric", value = "Value") %>%
  separate(Metric, into = c("Item", "Statistic"),
           sep = "_(?=Mean|SD|Skewness|Kurtosis)", remove = TRUE) %>%
  spread(key = "Statistic", value = "Value")

kk(dt_individual, "Digital Transformation Individual Items - Descriptive Statistics")




# Business Model Alignment
bma_individual <- digital_df %>%
  select(starts_with("bma_")) %>%
  select(-ends_with("_score"), -ends_with("_centered")) %>%   # exclude composite
  summarise_all(list(
    Mean     = ~round(mean(., na.rm = TRUE), 3),
    SD       = ~round(sd(., na.rm = TRUE), 3),
    Skewness = ~round(skewness(., na.rm = TRUE), 3),
    Kurtosis = ~round(kurtosis(., na.rm = TRUE), 3)
  )) %>%
  gather(key = "Metric", value = "Value") %>%
  separate(Metric, into = c("Item", "Statistic"),
           sep = "_(?=Mean|SD|Skewness|Kurtosis)", remove = TRUE) %>%
  spread(key = "Statistic", value = "Value")

kk(bma_individual, "Business Model Alignment Individual Items - Descriptive Statistics")


# Customer Demand
cd_individual <- digital_df %>%
  select(starts_with("cd_")) %>%
  select(-ends_with("_score"), -ends_with("_centered")) %>%
  summarise_all(list(
    Mean     = ~round(mean(., na.rm = TRUE), 3),
    SD       = ~round(sd(., na.rm = TRUE), 3),
    Skewness = ~round(skewness(., na.rm = TRUE), 3),
    Kurtosis = ~round(kurtosis(., na.rm = TRUE), 3)
  )) %>%
  gather(key = "Metric", value = "Value") %>%
  separate(Metric, into = c("Item", "Statistic"),
           sep = "_(?=Mean|SD|Skewness|Kurtosis)", remove = TRUE) %>%
  spread(key = "Statistic", value = "Value")

kk(cd_individual, "Customer Demand Individual Items - Descriptive Statistics")


# Financial Health
fh_individual <- digital_df %>%
  select(starts_with("fh_")) %>%
  select(-ends_with("_score"), -ends_with("_centered")) %>%
  summarise_all(list(
    Mean     = ~round(mean(., na.rm = TRUE), 3),
    SD       = ~round(sd(., na.rm = TRUE), 3),
    Skewness = ~round(skewness(., na.rm = TRUE), 3),
    Kurtosis = ~round(kurtosis(., na.rm = TRUE), 3)
  )) %>%
  gather(key = "Metric", value = "Value") %>%
  separate(Metric, into = c("Item", "Statistic"),
           sep = "_(?=Mean|SD|Skewness|Kurtosis)", remove = TRUE) %>%
  spread(key = "Statistic", value = "Value")

kk(fh_individual, "Financial Health Individual Items - Descriptive Statistics")







plot_data <- digital_df %>%
  select(DT_score, BMA_score, FH_score, CD_score) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Score") %>%
  filter(!is.na(Score)) %>%   # remove missing values
  mutate(Variable = case_when(
    Variable == "DT_score" ~ "Digital Transformation",
    Variable == "BMA_score" ~ "Business Model Alignment",
    Variable == "FH_score" ~ "Financial Health",
    Variable == "CD_score" ~ "Customer Demand"
  ))


ggplot(plot_data, aes(x = Score, fill = Variable)) +
  geom_histogram(aes(y = after_stat(density)), bins = 15, alpha = 0.7, color = "white") +
  geom_density(alpha = 0.3, color = "black", linewidth = 1) +
  facet_wrap(~Variable, scales = "free") +
  scale_fill_viridis_d(option = "plasma") +
  labs(title = "Distribution of Main Study Variables", 
       subtitle = "Histograms with Density Curves",
       x = "Score", y = "Density") +
  theme(legend.position = "none")




# Box plots with jitter
 ggplot(plot_data, aes(x = Variable, y = Score, fill = Variable)) +
  geom_boxplot(alpha = 0.7, outlier.alpha = 0) +
  geom_jitter(width = 0.2, alpha = 0.3, size = 0.8) +
  scale_fill_viridis_d(option = "mako") +
  labs(title = "Box Plots of Main Study Variables", 
       subtitle = "With Individual Data Points",
       x = "Variable", y = "Score") +
  theme(legend.position = "none") 



 
 
 
```



Digital Transformation (DT_score): M = 3.83, SD = 0.82, Median = 4.00, Range = 1.29-5.00

Business Model Alignment (BMA_score): M = 3.85, SD = 0.79, Median = 4.00, Range = 1.00 - 5.00

Financial Health (FH_score): M = 3.52, SD = 0.58, Median = 3.67, Range = 1.83-4.50
Customer Demand (CD_score): M = 3.99, SD = 0.78, Median = 4.12, Range = 1.25 - 5.00

Individual items (e.g., dt_analytical_tools, bma_digital_revenue) show similar patterns, with means around 3.7-4.1 and SDs around 0.94-1.11, indicating positive perceptions and moderate variability.





```{r}

library(dplyr)
library(agricolae)
library(knitr)
library(kableExtra)
library(broom)

# Define scores and labels
scores <- list(
  DT_score  = "Digital Transformation Score",
  BMA_score = "Business Model Alignment Score",
  FH_score  = "Financial Health Score",
  CD_score  = "Customer Demand Score"
)

# --- Collect all ANOVA results ---
anova_all <- data.frame()

for (score_var in names(scores)) {
  
  score_label <- scores[[score_var]]
  
  # ANOVA
  anova_formula <- as.formula(paste(score_var, "~ firm_type"))
  anova_result <- aov(anova_formula, data = digital_df)
  anova_tidy <- tidy(anova_result) %>%
    filter(term == "firm_type") %>%   # keep only firm_type row
    mutate(Score = score_label)
  
  # Append
  anova_all <- bind_rows(anova_all, anova_tidy)
  
  # --- Post-hoc Tukey HSD (shown separately) ---
  tukey_result <- agricolae::HSD.test(anova_result, "firm_type", group = TRUE)
  tukey_table <- data.frame(
    Firm_Type = rownames(tukey_result$groups),
    Mean = round(tukey_result$groups[,1], 3),
    Group = tukey_result$groups[,2]
  )
  

    kable(tukey_table, caption = paste("Post-hoc Tukey HSD:", score_label)) %>%
      kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
  
}

# --- Final combined ANOVA table ---
anova_all <- anova_all %>%
  select(Score, df, sumsq, meansq, statistic, p.value)

kk(anova_all, caption = "Combined ANOVA Results by Firm Type") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))





# Example for Business Model Alignment Score
score_var <- "BMA_score"
score_label <- "Business Model Alignment Score"

# --- ANOVA ---
anova_formula <- as.formula(paste(score_var, "~ firm_type"))
anova_result <- aov(anova_formula, data = digital_df)
anova_tidy <- tidy(anova_result)



# --- Post-hoc Tukey HSD ---
tukey_result <- agricolae::HSD.test(anova_result, "firm_type", group = TRUE)
tukey_table <- data.frame(
  Firm_Type = rownames(tukey_result$groups),
  Mean = round(tukey_result$groups[,1], 3),
  Group = tukey_result$groups[,2]
)

kk(tukey_table, caption = paste("Post-hoc Tukey HSD:", score_label)) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))


score_var <- "DT_score"
score_label <- "Digital Transformation Score"

# --- ANOVA ---
anova_formula <- as.formula(paste(score_var, "~ firm_type"))
anova_result <- aov(anova_formula, data = digital_df)
anova_tidy <- tidy(anova_result)



# --- Post-hoc Tukey HSD ---
tukey_result <- agricolae::HSD.test(anova_result, "firm_type", group = TRUE)
tukey_table <- data.frame(
  Firm_Type = rownames(tukey_result$groups),
  Mean = round(tukey_result$groups[,1], 3),
  Group = tukey_result$groups[,2]
)

kk(tukey_table, caption = paste("Post-hoc Tukey HSD:", score_label)) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed")) 







```


ANOVA by Firm Type

Significant Differences:

DT_score: F(4,230) = 2.48, p = 0.04. Post-hoc Tukey HSD shows Healthcare (M = 4.03) and Consulting (M = 4.01) have higher means, but groups are not significantly distinct (all share group “a”).

BMA_score: F(4,229) = 2.63, p = 0.04. Consulting (M = 4.05) is significantly higher than Hospitality (M = 3.55, group “b”), with others overlapping.

Non-significant:FH_score: F(4,230) = 1.19, p = 0.31
CD_score: F(4,230) = 0.65, p = 0.63

Firms in Consulting and Healthcare tend to report higher DT and BMA scores, suggesting industry-specific differences in digital adoption.


## Normality Tests



```{r normality_tests}

library(dplyr)
library(tidyr)
library(moments)
# Comprehensive normality testing
normality_results <- digital_df %>%
  select(DT_score, BMA_score, FH_score, CD_score) %>%
  gather(key = "Variable", value = "Score") %>%
  group_by(Variable) %>%
  summarise(
    N = n(),
    Shapiro_W = round(shapiro.test(Score)$statistic, 4),
    Shapiro_p = round(shapiro.test(Score)$p.value, 4),
    Skewness = round(skewness(Score), 3),
    Kurtosis = round(kurtosis(Score), 3),
    Normal_Distribution = ifelse(shapiro.test(Score)$p.value > 0.05, "Yes", "No"),
    .groups = 'drop'
  ) %>%
  mutate(Variable = case_when(
    Variable == "DT_score" ~ "Digital Transformation",
    Variable == "BMA_score" ~ "Business Model Alignment",
    Variable == "FH_score" ~ "Financial Health",
    Variable == "CD_score" ~ "Customer Demand"
  ))







kk(normality_results, "Normality Test Results and Distribution Assessment")


# Create Q-Q plots for each variable
qq_data <- digital_df %>%
  select(DT_score, BMA_score, FH_score, CD_score) %>%
  gather(key = "Variable", value = "Score") %>%
  mutate(Variable = case_when(
    Variable == "DT_score" ~ "Digital Transformation",
    Variable == "BMA_score" ~ "Business Model Alignment",
    Variable == "FH_score" ~ "Financial Health",
    Variable == "CD_score" ~ "Customer Demand"
  ))





ggplot(qq_data, aes(sample = Score)) +
  stat_qq(color = "steelblue", size = 1.5, alpha = 0.7, na.rm = TRUE) +
  stat_qq_line(color = "red", linewidth = 1.2, na.rm = TRUE) +
  facet_wrap(~Variable, scales = "free") +
  labs(
    title = "Q-Q Plots for Normality Assessment",
    x = "Theoretical Quantiles", 
    y = "Sample Quantiles"
  ) 
```



Skewness and Kurtosis:

DT: Skewness = -0.98, Kurtosis = 0.72 (moderately skewed, platykurtic)


BMA: Skewness = -1.02, Kurtosis = 0.82 (moderately skewed, platykurtic)

FH: Skewness = -0.71, Kurtosis = -0.06 (moderately skewed, near normal)

CD: Skewness = -1.35, Kurtosis = 2.03 (highly skewed, leptokurtic)

Shapiro-Wilk Tests:

All constructs show non-normal distributions (p < 0.001):

DT: W = 0.93

BMA: W = 0.92

FH: W = 0.95

CD: W = 0.88

Q-Q plots   show slight deviations from normality




Observations

Constructs have means around 3.5–4.0, indicating generally positive perceptions of DT, BMA, FH, and CD.

Non-normal distributions (especially CD_score) suggest the need for robust statistical methods (e.g., bootstrap, robust SE) in subsequent analyses.


Industry differences in DT and BMA scores highlight the influence of firm type, with Consulting and Healthcare leading in digital transformation efforts.



##  Correlation and Multicollinearity Analysis

```{r correlation_analysis}
# Correlation matrix with significance tests
cor_data <- digital_df %>% select(DT_score, BMA_score, FH_score, CD_score)
cor_results <- rcorr(as.matrix(cor_data))

# Extract correlations and p-values
cor_matrix <- cor_results$r
p_matrix <- cor_results$P

# Create correlation table
cor_table <- data.frame(
  Variable_Pair = c("DT-BMA", "DT-FH", "DT-CD", "BMA-FH", "BMA-CD", "FH-CD"),
  Correlation = round(c(cor_matrix[1,2], cor_matrix[1,3], cor_matrix[1,4], 
                       cor_matrix[2,3], cor_matrix[2,4], cor_matrix[3,4]), 3),
  P_Value = round(c(p_matrix[1,2], p_matrix[1,3], p_matrix[1,4], 
                   p_matrix[2,3], p_matrix[2,4], p_matrix[3,4]), 4),
  Significance = sapply(c(p_matrix[1,2], p_matrix[1,3], p_matrix[1,4], 
                         p_matrix[2,3], p_matrix[2,4], p_matrix[3,4]), 
                       function(p) ifelse(p < 0.001, "***", ifelse(p < 0.01, "**", 
                                         ifelse(p < 0.05, "*", "ns")))),
  Strength = sapply(abs(c(cor_matrix[1,2], cor_matrix[1,3], cor_matrix[1,4], 
                         cor_matrix[2,3], cor_matrix[2,4], cor_matrix[3,4])),
                   function(r) ifelse(r < 0.3, "Weak", ifelse(r < 0.7, "Moderate", "Strong")))
)

kk(cor_table, "Correlation Analysis with Significance Tests")

# Multicollinearity assessment
model_for_vif <- lm(BMA_score ~ DT_score + FH_score + CD_score, data = digital_df)
vif_values <- vif(model_for_vif)

multicollinearity_results <- data.frame(
  Variable = names(vif_values),
  VIF = round(vif_values, 3),
  Tolerance = round(1/vif_values, 3),
  VIF_Assessment = ifelse(vif_values < 5, "Acceptable", 
                         ifelse(vif_values < 10, "Concerning", "Problematic"))
)

kk(multicollinearity_results, "Multicollinearity Assessment")




# --- 5. Correlation heatmap ---
ggcorrplot(cor_matrix, 
           hc.order = TRUE, 
           type = "lower",
           outline.col = "white",
           colors = c("#E46726", "white", "dodgerblue"),
           lab = TRUE,
           lab_size = 4, ggtheme = theme_publication_presentation(),
           title = "Correlation Matrix Heatmap") +
  theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))


```


Correlations

All construct pairs show strong, significant correlations (p < 0.001):

DT-BMA: r = 0.86 (Strong),... and the others.


The correlation heatmap  visually confirms strong positive relationships


Multicollinearity:

Variance Inflation Factors (VIF) for the model predicting BMA_score:

DT_score: VIF = 3.13, Tolerance = 0.32

FH_score: VIF = 2.98, Tolerance = 0.34

CD_score: VIF = 2.51, Tolerance = 0.40

All VIFs are below 5, indicating acceptable levels of multicollinearity for regression analyses.

Observations

Strong correlations suggest that DT, BMA, FH, and CD are closely related, supporting the theoretical framework but raising concerns about construct distinctiveness (aligned with high HTMT ratios).


Acceptable VIF values ensure that multicollinearity is not a significant issue for regression models, allowing reliable estimation of effects.






# Exploratory Factor Analysis


```{r}
library(dplyr)
library(tibble)
library(psych)
library(knitr)

# --------------------------------------------------------
# 1) Prepare Likert item matrix (exclude composite scores)
# --------------------------------------------------------
likert_items <- digital_df %>%
  select(matches("^(dt_|bma_|fh_|cd_)")) %>%      # only original items
  select(-matches("_score$|^(DT|BMA|FH|CD)_score$")) %>%
  select(where(is.numeric)) %>%                  # keep numeric
  mutate(across(everything(), ~ as.integer(.)))  # convert to integer if not

likert_items <- digital_df %>%
  select(matches("^(dt_|bma_|fh_|cd_)")) %>%
  select(-matches("(_score$|_centered$)")) %>%
  select(where(is.numeric)) %>%
  mutate(across(everything(), ~ as.integer(.)))

# --------------------------------------------------------
# 2) Polychoric correlation matrix
# --------------------------------------------------------
poly_out <- psych::polychoric(likert_items)
Rpoly <- poly_out$rho





# --------------------------------------------------------
# 3) Factorability tests
# --------------------------------------------------------
kmo_result <- psych::KMO(Rpoly)
bartlett_result <- psych::cortest.bartlett(Rpoly, n = nrow(likert_items))

factorability_tests <- tibble(
  Test = c("Kaiser-Meyer-Olkin (KMO)", "Bartlett's Test of Sphericity"),
  Statistic = c(round(kmo_result$MSA, 2), round(bartlett_result$chisq, 2)),
  P_value = c("N/A", formatC(bartlett_result$p.value, format = "e", digits = 2))
)

kk(factorability_tests, "Factor Analysis Suitability (Polychoric)")

# --------------------------------------------------------
# 4) Factor retention check: Parallel Analysis & Scree
# --------------------------------------------------------
fa_parallel <- psych::fa.parallel(
  Rpoly,
  n.obs = nrow(likert_items),
  fm = "minres",
  fa = "fa"
)

suggested_factors <- fa_parallel$nfact
#cat("Parallel analysis suggests", suggested_factors, "factors\n")

# --------------------------------------------------------
# 5) Exploratory Factor Analysis (EFA) with oblimin rotation
# --------------------------------------------------------
n_factors <- suggested_factors  # or manually set, e.g., 3
efa_result <- psych::fa(
  Rpoly,
  nfactors = 3,
  fm = "minres",
  rotate = "oblimin",
  n.obs = nrow(likert_items),
  scores = "none"
)

# --------------------------------------------------------
# 6) Prepare factor loadings table
# --------------------------------------------------------
loading_cut <- 0.30
load_mat <- efa_result$loadings %>%
  unclass() %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Item")

num_cols <- setdiff(names(load_mat), "Item")
num_load <- load_mat[num_cols] %>% lapply(as.numeric) %>% as.data.frame()
rownames(num_load) <- load_mat$Item

pretty_load <- load_mat
pretty_load[num_cols] <- lapply(num_load, function(x) {
  ifelse(abs(x) < loading_cut, "", sprintf("%.3f", round(x, 3)))
})

factor_loadings <- pretty_load %>% select(Item, all_of(num_cols))

kk(factor_loadings, sprintf(
  "Exploratory Factor Analysis Loadings (Polychoric, minres, |loading| < %.2f suppressed)", 
  loading_cut
))



# EFA fit indices
tli <- round(efa_result$TLI, 3)
rms <- round(efa_result$rms, 3)
chi <- round(efa_result$chi, 3)
dof <- efa_result$dof
rmsea <- if(length(efa_result$RMSEA) > 0) round(efa_result$RMSEA[1], 3) else NA
pval <- if(length(efa_result$pval) > 0) round(as.numeric(efa_result$pval), 4) else NA

efa_fit <- data.frame(
  Measure = c(
    "Tucker Lewis Index (TLI)", 
    "Root Mean Square Residual (RMSR)", 
    "Chi-square", 
    "Degrees of Freedom", 
    "P-value", 
    "RMSEA"
  ),
  Value = c(tli, rms, chi, dof, pval, rmsea),
  Acceptable_Range = c("> 0.95", "< 0.08", "Non-significant", "-", "> 0.05", "< 0.08"),
  Interpretation = c(
    if(tli > 0.95) "Excellent fit" else if(tli > 0.90) "Good fit" else "Poor fit",
    if(rms < 0.05) "Excellent fit" else if(rms < 0.08) "Good fit" else "Poor fit",
    if(!is.na(pval) && pval > 0.05) "Good fit" else "Poor fit",
    "-", 
    if(!is.na(pval) && pval > 0.05) "Good fit" else "Poor fit",
    if(!is.na(rmsea) && rmsea < 0.05) "Excellent fit" else if(!is.na(rmsea) && rmsea < 0.08) "Good fit" else "Poor fit"
  )
)

kk(efa_fit, "EFA Model Fit Indices")





```





Exploratory Factor Analysis (EFA)

Factorability:KMO: 0.93 (excellent, indicating sufficient item correlations for factor analysis).

Bartlett’s Test: χ² = 7830.98, p < 0.001 (significant, confirming factorability).

 Parallel analysis recommends 3 factors, EFA was conducted with 3 factors.

Factor Loadings

Factor Loadings

MR1 (DT and BMA):

DT items: High loadings (e.g., dt_automation_productivity: 0.893, dt_process_integration: 0.772, dt_it_infrastructure: 0.758).

BMA items: Strong loadings (e.g., bma_collaboration: 0.827, bma_platform_models: 0.795, bma_digital_revenue: 0.755).

FH items: Moderate loadings (e.g., fh_cost_reduction: 0.562, fh_liquidity_ratios: 0.555, fh_project_capability: 0.463).

Interpretation: This factor captures digital transformation and business model alignment, with some financial health aspects, suggesting DT and BMA are closely related.



MR2 (CD):

CD items: High loadings (e.g., cd_response_speed: 0.848, cd_speed_convenience: 0.770, cd_personalization: 0.741).

Interpretation: This factor clearly represents customer demand, aligning with the CD construct.

MR3 (FH Constraints)

FH items: Dominated by fh_constraints_delay (0.856) and fh_constraints_delay_rev (-0.856).

Minor loading: fh_roi_tracking (0.395), fh_longterm_evaluation (0.304).

Interpretation: This factor isolates financial constraints, highlighting the distinct role of financial barriers in FH.

Cross-Loadings: bma_competitive_advantage (MR1: 0.503, MR3: 0.337) and fh_roi_tracking (MR1: 0.518, MR3: 0.395) show minor cross-loadings.

Observations:

The 3-factor solution better aligns with parallel analysis, reducing overfitting by combining DT and BMA into a single factor (MR1), reflecting their high correlation (r = 0.86) and HTMT ratio (0.95).

CD (MR2) is distinct, supporting its role as a mediator in RQ3.
FH constraints (MR3) highlight financial barriers as a unique aspect, though other FH items load on MR1, suggesting financial health partially overlaps with DT/BMA.

Poor fit indices (TLI, RMSEA) indicate that the 3-factor model still does not fully capture the data structure,  due to complex item relationships and or non-normality.





Implications and Limitations

Theoretical Implications:The 3-factor EFA suggests that DT and BMA are not fully distinct, supporting their strong correlation (r = 0.86) and high HTMT ratio (0.95). This implies that digital transformation may inherently drive business model alignment in service firms.

CD’s distinct factor (MR2) supports its role as a mediator (RQ3), while FH’s split (MR1 and MR3) suggests financial health has both enabling (e.g., cost reduction) and constraining (e.g., financial barriers) dimensions, relevant for RQ2.

Industry differences (Consulting and Healthcare leading in DT and BMA) underscore the need for contextual factors in theoretical models of digital transformation.

Practical Implications:Firms should recognize the interdependence of DT and BMA, investing in digital tools that directly enhance business model innovation (e.g., digital channels, platform models).
Consulting and Healthcare firms can leverage their high DT and BMA scores for competitive advantage, while Hospitality firms may need support to address lower scores.
Addressing financial constraints (MR3) is critical for firms with limited resources to maximize DT benefits.



Conclusion

The preliminary analyses confirm the dataset’s suitability for addressing RQ1 (DT’s impact on BMA), RQ2 (FH’s moderation), and RQ3 (CD’s mediation), with reliable and convergently valid measures. The 3-factor EFA reduces overfitting by combining DT and BMA, aligning with their strong correlation and high HTMT ratio, but poor fit indices and discriminant validity issues persist. 

Key findings include:Construct Overlap: DT and BMA form a single factor (MR1), suggesting they are closely intertwined, complicating causal separation in RQ1.
Distinct Constructs: CD (MR2) is distinct, supporting its mediation role, while FH (MR1 and MR3) reflects both enabling and constraining aspects.

Non-normality: All constructs are non-normal, requiring robust methods.

Industry Variation: Consulting and Healthcare lead in DT and BMA, relevant for contextual analyses.



#  Research Question 1: Direct Effect Analysis
- Objective 1.  Examine the relationship between digital transformation and service business models

**Hypothesis H1:** Digital transformation positively affects service business models

```{r rq1_comprehensive}
library(dplyr)
library(lm.beta)
library(gtools) # For stars.pval

# Model 1: Direct effect
model1 <- lm(BMA_score ~ DT_score, data = digital_df)
model1_summary <- summary(model1)

# Comprehensive results table
rq1_results <- data.frame(
  Variable = c("(Intercept)", "Digital Transformation"),
  Beta = round(coef(model1), 3),
  Std_Beta = c(NA, round(lm.beta(model1)$standardized.coefficients[2], 3)),
  SE = round(model1_summary$coefficients[,2], 3),
  t_value = round(model1_summary$coefficients[,3], 3),
  P_value = round(model1_summary$coefficients[,4], 4),
  CI_Lower = round(confint(model1)[,1], 3),
  CI_Upper = round(confint(model1)[,2], 3),
  Significance = sapply(model1_summary$coefficients[,4], 
                       function(p) ifelse(p < 0.001, "***", ifelse(p < 0.01, "**", 
                                         ifelse(p < 0.05, "*", "ns"))))
)

kk(rq1_results, "RQ1: Direct Effect of Digital Transformation on Business Models")

# Effect size calculations
cohens_f2 <- model1_summary$r.squared / (1 - model1_summary$r.squared)
effect_size_interpretation <- ifelse(cohens_f2 < 0.02, "Small", 
                                   ifelse(cohens_f2 < 0.15, "Medium", "Large"))

# Model diagnostics
rq1_diagnostics <- data.frame(
  Statistic = c("R-squared", "Adjusted R-squared", "F-statistic", "F p-value", 
                "Standard Error", "Cohen's f²", "Effect Size", "Durbin-Watson"),
  Value = c(round(model1_summary$r.squared, 3),
            round(model1_summary$adj.r.squared, 3),
            round(model1_summary$fstatistic[1], 3),
            round(pf(model1_summary$fstatistic[1], model1_summary$fstatistic[2], 
                     model1_summary$fstatistic[3], lower.tail = FALSE), 4),
            round(model1_summary$sigma, 3),
            round(cohens_f2, 3),
            effect_size_interpretation,
            round(durbinWatsonTest(model1)$dw, 3))
)

kk(rq1_diagnostics, "RQ1: Model Fit and Diagnostics")

# Residual analysis
par(mfrow = c(2, 2))
plot(model1, main = "RQ1: Residual Diagnostics")
par(mfrow = c(1, 1))

# Regression plot
ggplot(digital_df, aes(x = DT_score, y = BMA_score)) +
  geom_point(alpha = 0.6, color = "dodgerblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  labs(title = "RQ1: Digital Transformation → Business Model Alignment",
       subtitle = paste0("β = ", round(coef(model1)[2], 3), ", R² = ", round(model1_summary$r.squared, 3),
                         ", p ", ifelse(model1_summary$coefficients[2,4] < 0.001, "< 0.001", 
                                       paste("=", round(model1_summary$coefficients[2,4], 3)))),
       x = "Digital Transformation Score", 
       y = "Business Model Alignment Score")
```



**RQ1 Conclusion:** Digital transformation `r ifelse(model1_summary$coefficients[2,4] < 0.05, "significantly and positively", "does not significantly")` affects business model alignment (β = `r round(coef(model1)[2], 3)`, p = `r round(model1_summary$coefficients[2,4], 4)`). The model explains `r round(model1_summary$r.squared * 100, 1)`% of the variance with a `r effect_size_interpretation` effect size.





Regression Results (RQ1: Direct Effect of Digital Transformation on Business Models):

Model: BMA_score ~ DT_score

Intercept: β = 0.69, SE = 0.13, t = 5.47, p < 0.001 (***), 95% CI [0.44, 0.94]

Digital Transformation (DT_score): β = 0.82, Std. β = 0.86, SE = 0.03, t = 25.46, p < 0.001 (***), 95% CI [0.76, 0.89]

Interpretation: The regression coefficient (β = 0.82) indicates that a one-unit increase in DT_score is associated with a 0.82-unit increase in BMA_score, holding all else constant. The standardized beta (Std. β = 0.86) suggests a strong positive effect, confirming that digital transformation significantly enhances service business model alignment. The highly significant p-value (<0.001) supports Hypothesis H1, indicating a robust positive relationship between digital transformation and service business models.

Effect Size:

R-squared: 0.736, indicating that 73.6% of the variance in BMA_score is explained by DT_score.

Adjusted R-squared: 0.735, confirming the model’s explanatory power after adjusting for degrees of freedom.

Cohen’s f²: 2.793, classified as a Large effect size (f² > 0.35), underscoring the substantial impact of digital transformation on business model alignment.

Model Fit and Diagnostics:

F-statistic: 648.079, p < 0.001, indicating that the model is statistically significant overall.

Standard Error of the Estimate: 0.407, suggesting moderate residual variability.

Durbin-Watson Statistic: 2.136 (close to 2), indicating no significant autocorrelation in the residuals, supporting the model’s assumption of independence.

Residual Diagnostics: The provided code references residual plots , which typically include residual vs. fitted, Q-Q, scale-location, and residual vs. leverage plots.  to help assess linearity, normality, homoscedasticity, and influential points.

The regression plot shows a strong linear relationship between DT_score and BMA_score, with a slope of β = 0.82 and R² = 0.736. 






- Key Observations  for RQ1

Strong Positive Effect: The regression results (β = 0.82, Std. β = 0.86, R² = 0.736) provide robust evidence that digital transformation positively affects service business models, strongly supporting Hypothesis H1. The large effect size (Cohen’s f² = 2.793) indicates that DT is a critical driver of business model innovation, particularly through digital revenue streams, platform-based models, and improved customer satisfaction.

EFA Support: Exploratory Factor Analysis (EFA) shows DT and BMA items loading strongly on the same factor (MR1, loadings 0.503–0.893), reinforcing their conceptual linkage.


Firm-Type Variations: ANOVA results show significant differences in BMA_score across firm types (F = 2.63, p = 0.04), with Consulting/Professional Services (Mean = 4.05) scoring highest and Hospitality (Mean = 3.55) lowest, suggesting industry-specific DT impacts.


Qualitative insights

Benefits: Open-ended responses highlight improved efficiency (22.6%), better customer experience (25.1%), and data-driven decision-making (17.0%) as top DT benefits, aligning with BMA items like bma_customer_satisfaction and bma_digital_channels.

Challenges: High costs (13.2%), resistance to change (11.1%), and data security concerns (10.6%) may temper DT’s impact on BMA.

Recommendations: Developing a clear digital strategy (6.4%) and investing in training (17.4%) support DT items like dt_leadership_support and dt_staff_training, enhancing BMA.






Implications:
 
Firms that invest in DT initiatives (e.g., automation, IT infrastructure, analytical tools) are likely to see significant improvements in their business models, such as adopting digital channels or subscription models. This is particularly evident in Consulting/Professional Services, where high DT and BMA scores suggest a model for success.

-  Conclusion for RQ1

The analysis provides compelling evidence that digital transformation has a strong, positive impact on service business models, as evidenced by the regression results (β = 0.82, Std. β = 0.86, R² = 0.736, p < 0.001) and supported by a large effect size (Cohen’s f² = 2.793). This confirms Hypothesis H1, showing that DT initiatives like automation, analytics, and IT infrastructure drive business model innovations such as digital revenue streams, platform models, and enhanced customer satisfaction. Open-ended responses and high item means further corroborate these findings, highlighting efficiency, customer experience, and data-driven decisions as key outcomes. While challenges like costs and resistance to change exist, the strong DT-BMA relationship underscores the transformative potential of digital initiatives in service industries, particularly in Consulting/Professional Services.






#  Research Question 2: Moderation Analysis

**Hypothesis H2:** Financial health moderates the relationship between digital transformation and service business models

```{r rq2_comprehensive}
# Model 2: Moderation with interaction
model2 <- lm(BMA_score ~ DT_centered + FH_centered + DT_centered:FH_centered, data = digital_df)
model2_summary <- summary(model2)

# Comprehensive moderation results
rq2_results <- data.frame(
  Variable = c("(Intercept)", "Digital Transformation", "Financial Health", "DT × FH Interaction"),
  Beta = round(coef(model2), 3),
  Std_Beta = c(NA, round(lm.beta(model2)$standardized.coefficients[2:4], 3)),
  SE = round(model2_summary$coefficients[,2], 3),
  t_value = round(model2_summary$coefficients[,3], 3),
  P_value = round(model2_summary$coefficients[,4], 4),
  CI_Lower = round(confint(model2)[,1], 3),
  CI_Upper = round(confint(model2)[,2], 3),
  Significance = sapply(model2_summary$coefficients[,4], 
                       function(p) ifelse(p < 0.001, "***", ifelse(p < 0.01, "**", 
                                         ifelse(p < 0.05, "*", "ns"))))
)

kk(rq2_results, "RQ2: Moderation Analysis Results")

# Model comparison tests
anova_comparison <- anova(model1, model2)
r2_change <- model2_summary$r.squared - model1_summary$r.squared

model_comparison_rq2 <- data.frame(
  Model = c("Model 1: Direct Effect", "Model 2: Moderation"),
  R_squared = c(round(model1_summary$r.squared, 3), round(model2_summary$r.squared, 3)),
  Adj_R_squared = c(round(model1_summary$adj.r.squared, 3), round(model2_summary$adj.r.squared, 3)),
  R_squared_Change = c("--", round(r2_change, 3)),
  F_Change = c("--", round(anova_comparison$F[2], 3)),
  F_Change_p = c("--", round(anova_comparison$`Pr(>F)`[2], 4)),
  AIC = c(round(AIC(model1), 1), round(AIC(model2), 1)),
  BIC = c(round(BIC(model1), 1), round(BIC(model2), 1))
)

kk(model_comparison_rq2, "RQ2: Model Comparison and Change Statistics")


# Moderation analysis (continued)
library(lmtest)
library(sandwich)
library(ggplot2)
library(kableExtra)

# Robust standard errors
robust_model2 <- coeftest(model2, vcov = vcovHC(model2, type = "HC3"))

rq2_results_robust <- data.frame(
  Variable = c("(Intercept)", "Digital Transformation", "Financial Health", "DT × FH Interaction"),
  Beta = round(coef(model2), 3),
  Std_Beta = c(NA, round(lm.beta(model2)$standardized.coefficients[2:4], 3)),
  Robust_SE = round(robust_model2[,2], 3),
  t_value = round(robust_model2[,3], 3),
  P_value = round(robust_model2[,4], 4),
  Significance = sapply(robust_model2[,4], 
                       function(p) ifelse(p < 0.001, "***", ifelse(p < 0.01, "**", 
                                         ifelse(p < 0.05, "*", "ns"))))
)

kk(rq2_results_robust, "RQ2: Moderation Analysis with Robust Standard Errors")

# Simple slopes analysis
fh_sd <- sd(digital_df$FH_centered, na.rm = TRUE)
simple_slopes <- data.frame(
  FH_Level = c("Low (-1 SD)", "Mean", "High (+1 SD)"),
  Slope = round(coef(model2)[2] + coef(model2)[4] * c(-fh_sd, 0, fh_sd), 3),
  SE = round(sqrt(diag(vcov(model2))[2] + c(-fh_sd, 0, fh_sd)^2 * diag(vcov(model2))[4] + 
                  2 * c(-fh_sd, 0, fh_sd) * vcov(model2)[2,4]), 3)
) %>%
  mutate(
    t_value = round(Slope / SE, 3),
    P_value = round(2 * pt(abs(t_value), df = model2_summary$df[2], lower.tail = FALSE), 4),
    Significance = sapply(P_value, function(p) ifelse(p < 0.001, "***", ifelse(p < 0.01, "**", ifelse(p < 0.05, "*", "ns")))),
    Interpretation = ifelse(P_value < 0.05, "Significant Effect", "Non-significant Effect")
  )

kk(simple_slopes, "RQ2: Simple Slopes Analysis for DT × FH Interaction")

# Interaction plot
plot_data <- digital_df %>%
  mutate(FH_Level = case_when(
    FH_centered <= -fh_sd ~ "Low (-1 SD)",
    FH_centered >= fh_sd ~ "High (+1 SD)",
    TRUE ~ "Mean"
  ))

ggplot(plot_data, aes(x = DT_centered, y = BMA_score, color = FH_Level)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_manual(values = c("Low (-1 SD)" = "blue", "Mean" = "black", "High (+1 SD)" = "red")) +
  labs(title = "Moderation Effect: DT on BMA by Financial Health",
       x = "Digital Transformation (Centered)", 
       y = "Business Model Alignment",
       color = "Financial Health Level") 









# Run tests
 bptest(model2)
 durbinWatsonTest(model2)



```

**RQ2 Conclusion**

Financial health `r ifelse(model2_summary$coefficients[4,4] < 0.05, 
                           "significantly moderates", 
                           "does not significantly moderate")` 
the relationship between digital transformation and business model alignment 
(β = `r round(coef(model2)[4], 3)`, p = `r round(model2_summary$coefficients[4,4], 4)`).  

The interaction explains an additional `r round(r2_change * 100, 1)`% of variance 
(ΔR² = `r round(r2_change, 3)`).




Regression Results (RQ2: Moderation Analysis Results):

Model: BMA_score ~ DT_centered + FH_centered + DT_centered:FH_centered

Intercept: β = 3.88, SE = 0.03, t = 132.75, p = 0 (***), 95% CI [3.82, 3.93]

Digital Transformation (DT_centered): β = 0.54, Std. β = 0.57, SE = 0.05, t = 10.43, p = 0 (***), 95% CI [0.44, 0.65]


Financial Health (FH_centered): β = 0.44, Std. β = 0.32, SE = 0.07, t = 6.47, p = 0 (***), 95% CI [0.31, 0.58]


DT × FH Interaction: β = -0.07, Std. β = -0.06, SE = 0.04, t = -1.67, p = 0.1 (ns), 95% CI [-0.16, 0.01]

Interpretation: The non-significant interaction term (β = -0.07, p = 0.1) indicates that FH does not significantly moderate the DT-BMA relationship in Model 2, failing to support H2. However, FH has a significant direct effect (β = 0.44, p < 0.001), suggesting it independently enhances BMA. In Model 4, the interaction is significant (β = -0.19, p = 0.02), implying a negative moderation where higher FH slightly weakens DT's effect on BMA.


Effect Size

R-squared: 0.78, indicating 78% variance explained.

Adjusted R-squared: 0.78.

Cohen’s f²: 0.73 (Large effect for FH in Model 4).

Model Fit and Diagnostics:F-statistic: 271.69, p < 0.001.

R² Change: 0.044, F Change = 22.747, p < 0.001.

AIC = 208.8, BIC = 226.0 (improved over Model 1).

Durbin-Watson: 2.087, p = 0.504 (no autocorrelation).

The interaction plot shows DT's effect on BMA weakens slightly at higher FH levels, but the interaction is non-significant in Model 2.

- Key Observations for RQ2:

The non-significant interaction in Model 2 (p = 0.10) and SEM (p = 0.80) suggests that financial health does not strongly moderate the DT-BMA relationship, failing to fully support Hypothesis H2. However, the significant interaction in Model 4 (p = 0.02) indicates a potential moderating effect, where higher FH slightly weakens the DT-BMA relationship, possibly due to diminishing returns in well-funded firms.
FH has a strong direct effect on BMA (β = 0.44, p < 0.001), suggesting it is an important enabler of business model alignment, likely through funding DT initiatives.

The simple slopes analysis shows that DT’s effect on BMA remains strong across FH levels, but the negative interaction coefficient in Model 4 suggests that firms with high FH may rely less on DT for BMA, possibly due to established processes.


Observations:

FH_score: Mean = 3.525, Median = 3.667, SD = 0.58, with high scores on fh_cost_reduction (Mean = 3.889) and fh_liquidity_ratios (Mean = 3.881). The item fh_constraints_delay (Mean = 3.864) and its reversed version (fh_constraints_delay_rev, Mean = 2.136) suggest moderate financial constraints.

Strong correlations with DT (r = 0.78) and BMA (r = 0.80) indicate FH’s importance, but the non-significant interaction in Model 2 suggests its moderating role is limited.

Challenges: Financial costs (13.2%) are a key barrier, aligning with fh_constraints_delay, suggesting that financial constraints may limit DT’s impact on BMA in some firms.

Recommendations: Strategies like scalable technologies (4.3%) and leadership support (5.1%) may mitigate financial constraints, supporting FH’s role in enabling DT.

Implications:FH is an enabler rather than a strong moderator; firms should prioritize financial stability to support DT investments.

Conclusion for RQ2


Financial health does not significantly moderate the relationship between digital transformation and business model alignment in Model 2 (β = -0.07, p = 0.1), though Model 4 suggests a negative moderation (β = -0.19, p = 0.02). The interaction explains an additional 4.4% of variance (ΔR² = 0.044). H2 receives mixed support, with FH acting as a significant direct predictor (β = 0.44) but not a reliable moderator. This implies FH enables BMA independently, with qualitative insights emphasizing cost barriers.





# Research Question 3: Mediation Analysis

**Hypothesis H3**: Customer demand mediates the relationship between digital transformation and service business models.


```{r rq3_analysis}
# Mediation analysis following Baron & Kenny (1986) steps

library(dplyr)
library(mediation)
library(lm.beta)
library(psych)
library(ggplot2)
library(grid) # for arrow units

# -------------------------
# 1) Define models
# -------------------------
# Total effect: DT → BMA
model_total <- lm(BMA_score ~ DT_score, data = digital_df)

# Mediation models
model_a <- lm(CD_score ~ DT_score, data = digital_df)              # a path
model_b <- lm(BMA_score ~ DT_score + CD_score, data = digital_df)  # b & c'



# -------------------------
# 0) Prepare complete-case dataset
# -------------------------
med_df <- digital_df %>%
  select(DT_score, CD_score, BMA_score) %>%
  drop_na()   # remove rows with any NA

# -------------------------
# 1) Fit models on complete data
# -------------------------
model_a <- lm(CD_score ~ DT_score, data = med_df)              # a path
model_b <- lm(BMA_score ~ DT_score + CD_score, data = med_df)  # b & c'

# Total effect model
model_total <- lm(BMA_score ~ DT_score, data = med_df)


# -------------------------
# 2) Mediation analysis
# -------------------------
set.seed(123)
med_fit <- mediate(model_a, model_b, treat = "DT_score", mediator = "CD_score",
                   boot = TRUE, sims = 1000)

# Extract path coefficients
a_path       <- coef(model_a)["DT_score"]
b_path       <- coef(model_b)["CD_score"]
c_prime_path <- coef(model_b)["DT_score"]
total_effect <- coef(model_total)["DT_score"]
indirect_effect <- a_path * b_path
mediation_ratio <- indirect_effect / total_effect

# -------------------------
# 3) Sobel test (optional)
# -------------------------
se_a <- summary(model_a)$coefficients["DT_score", "Std. Error"]
se_b <- summary(model_b)$coefficients["CD_score", "Std. Error"]
sobel_se <- sqrt(b_path^2 * se_a^2 + a_path^2 * se_b^2)
sobel_z  <- indirect_effect / sobel_se
sobel_p  <- 2 * (1 - pnorm(abs(sobel_z)))


# Define a small helper function for significance stars
p_stars <- function(p) {
  ifelse(p < 0.001, "***",
         ifelse(p < 0.01, "**",
                ifelse(p < 0.05, "*", "ns")))
}

# -------------------------
# 4) Mediation paths table
# -------------------------
mediation_paths <- data.frame(
  Path = c("a (DT → CD)", "b (CD → BMA | DT)", "c (DT → BMA)", 
           "c' (DT → BMA | CD)", "Indirect Effect (a × b)"),
  Coefficient = c(round(a_path, 3), round(b_path, 3), round(total_effect, 3),
                  round(c_prime_path, 3), round(indirect_effect, 3)),
  Std_Coefficient = c(round(lm.beta(model_a)$standardized.coefficients["DT_score"], 3),
                      round(lm.beta(model_b)$standardized.coefficients["CD_score"], 3),
                      round(lm.beta(model_total)$standardized.coefficients["DT_score"], 3),
                      round(lm.beta(model_b)$standardized.coefficients["DT_score"], 3),
                      NA),
  SE = c(round(se_a, 3), round(se_b, 3),
         round(summary(model_total)$coefficients["DT_score", "Std. Error"], 3),
         round(summary(model_b)$coefficients["DT_score", "Std. Error"], 3),
         round(sobel_se, 3)),
  t_or_z_value = c(round(summary(model_a)$coefficients["DT_score", "t value"], 3),
                   round(summary(model_b)$coefficients["CD_score", "t value"], 3),
                   round(summary(model_total)$coefficients["DT_score", "t value"], 3),
                   round(summary(model_b)$coefficients["DT_score", "t value"], 3),
                   round(sobel_z, 3)),
  P_value = c(round(summary(model_a)$coefficients["DT_score", "Pr(>|t|)"], 4),
              round(summary(model_b)$coefficients["CD_score", "Pr(>|t|)"], 4),
              round(summary(model_total)$coefficients["DT_score", "Pr(>|t|)"], 4),
              round(summary(model_b)$coefficients["DT_score", "Pr(>|t|)"], 4),
              round(sobel_p, 4)),
  Significance = p_stars(c(summary(model_a)$coefficients["DT_score", "Pr(>|t|)"],
                            summary(model_b)$coefficients["CD_score", "Pr(>|t|)"],
                            summary(model_total)$coefficients["DT_score", "Pr(>|t|)"],
                            summary(model_b)$coefficients["DT_score", "Pr(>|t|)"],
                            sobel_p))
)


kk(mediation_paths, "Mediation Analysis Path Coefficients")

# -------------------------
# 5) Mediation summary table
# -------------------------
mediation_summary <- data.frame(
  Effect_Type = c("Total Effect (c)", "Direct Effect (c')", "Indirect Effect (a × b)", 
                  "Proportion Mediated", "Sobel Test Result", 
                  "Bootstrap Indirect Effect", "Bootstrap CI Lower", "Bootstrap CI Upper"),
  Value = c(round(total_effect, 3),
            round(c_prime_path, 3),
            round(indirect_effect, 3),
            round(mediation_ratio, 3),
            ifelse(sobel_p < 0.05, paste("Significant (p =", round(sobel_p,4), ")"),
                   paste("Not significant (p =", round(sobel_p,4), ")")),
            round(med_fit$d.avg, 3),
            round(med_fit$d.avg.ci[1], 3),
            round(med_fit$d.avg.ci[2], 3)),
  Interpretation = c("Total effect of DT on BMA",
                     "Direct effect controlling for CD",
                     "Mediated effect through CD",
                     paste0(round(mediation_ratio*100,1), "% of total effect"),
                     "Sobel test for indirect effect",
                     "Mean bootstrap indirect effect",
                     "Bootstrap 95% CI lower bound",
                     "Bootstrap 95% CI upper bound")
)

kk(mediation_summary, "Mediation Effect Summary and Interpretation")

# -------------------------
# 6) Mediation path diagram (simplified)
# -------------------------
path_data <- data.frame(
  Path = c("DT → CD (a)", "CD → BMA (b)", "DT → BMA (c')"),
  Coefficient = c(a_path, b_path, c_prime_path),
  x = c(0, 1, 0),
  y = c(1, 0, 0),
  xend = c(1, 1, 1),
  yend = c(1, 0, 0)
)

node_positions <- data.frame(
  x = c(0, 1, 1),
  y = c(1, 1, 0),
  label = c("DT_score", "CD_score", "BMA_score")
)

ggplot() +
  geom_segment(data = path_data,
               aes(x = x, y = y, xend = xend, yend = yend),
               arrow = arrow(length = unit(0.2, "cm")), linewidth = 1) +
  geom_text(data = path_data, aes(x = (x+xend)/2, y = (y+yend)/2 + 0.05,
                                  label = paste0(Path, "\nβ=", round(Coefficient,3))),
            size = 4) +
  geom_point(data = node_positions, aes(x = x, y = y), size = 5) +
  geom_text(data = node_positions, aes(x = x, y = y + 0.05, label = label), size = 4) +
  labs(title = "Mediation Path Diagram") +
  theme_void()




# Bootstrap confidence intervals for indirect effect
set.seed(123)
n_bootstrap <- 1000
bootstrap_indirect <- replicate(n_bootstrap, {
  boot_indices <- sample(nrow(digital_df), replace = TRUE)
  boot_data <- digital_df[boot_indices, ]
  
  # Calculate a and b paths
  a_boot <- coef(lm(CD_score ~ DT_score, data = boot_data))[2]
  b_boot <- coef(lm(BMA_score ~ DT_score + CD_score, data = boot_data))[3]
  
  return(a_boot * b_boot)
})

# Calculate 95% confidence interval
ci_indirect <- quantile(bootstrap_indirect, c(0.025, 0.975), na.rm = TRUE)

bootstrap_results <- data.frame(
  Method = "Bootstrap (1000 iterations)",
  Indirect_Effect = round(mean(bootstrap_indirect, na.rm = TRUE), 3),
  CI_Lower = round(ci_indirect[1], 3),
  CI_Upper = round(ci_indirect[2], 3),
  CI_Contains_Zero = ifelse(ci_indirect[1] <= 0 & ci_indirect[2] >= 0, "Yes", "No"),
  Interpretation = ifelse(ci_indirect[1] <= 0 & ci_indirect[2] >= 0, 
                         "No significant mediation", "Significant mediation")
)

kk(bootstrap_results, "Bootstrap Confidence Intervals for Indirect Effect")
```






**RQ3 Conclusion**

Customer demand `r ifelse(med_fit$d.avg.p < 0.05, 
                          "significantly mediates", 
                          "does not significantly mediate")` 
the relationship between digital transformation and business model alignment 
(Indirect effect = `r round(indirect_effect, 3)`, p = `r round(med_fit$d.avg.p, 4)`).  

The mediated effect accounts for `r round(mediation_ratio * 100, 1)`% of the total effect.


Mediation Results (RQ3: Mediation Analysis Path Coefficients):

Model: CD_score ~ DT_score; BMA_score ~ DT_score + CD_score

a (DT → CD): β = 0.70, Std_Coefficient = 0.74, SE = 0.04, t_or_z_value = 16.79, P_value = 0

b (CD → BMA | DT): β = 0.16, Std_Coefficient = 0.16, SE = 0.05, t_or_z_value = 3.23, P_value = 0.001

c (DT → BMA): β = 0.82, Std_Coefficient = 0.86, SE = 0.03, t_or_z_value = 25.46, P_value = 0

c' (DT → BMA | CD): β = 0.71, Std_Coefficient = 0.74, SE = 0.05, t_or_z_value = 15.06, P_value = 0

Indirect Effect (a × b): Coefficient = 0.11, SE = 0.04, t_or_z_value = 3.17, P_value = 0.0015

Interpretation: Customer demand partially mediates the DT-BMA relationship, supporting Hypothesis H3. Approximately 13.7% of DT’s effect on BMA is channeled through CD, indicating that DT enhances BMA both directly and by increasing customer demand for digital services.

Effect Size:Total Effect: 0.824

Direct Effect: 0.711

Indirect Effect: 0.113 (13.7% of total effect)

Bootstrap Indirect Effect = 0.113, CI [0.031, 0.216] (does not contain zero, significant mediation).

Model Fit and Diagnostics:

R-squared: 0.75, indicating 75% variance explained.

F-statistic: 342.42, p < 0.001.

Sobel Test: Significant (p = 0.0015).

The mediation path diagram shows a strong a path (β = 0.703) and moderate b path (β = 0.161), with a direct c' path (β = 0.711).

- Key Observations for RQ3

The significant indirect effect (0.113, p = 0.001) and bootstrap CI [0.031, 0.216] confirm that CD partially mediates the DT-BMA relationship, supporting Hypothesis H3. DT enhances customer demand (e.g., for speed and personalization), which in turn drives BMA (e.g., through digital channels and platform models).

The non-significant CD effect in Model 4 and SEM suggests that CD’s influence is primarily indirect, with DT remaining the dominant direct predictor of BMA.
High CD scores and qualitative emphasis on customer experience highlight CD as a key external driver, pushing firms to align business models with digital expectations.

The discrepancy between regression-based mediation (significant) and SEM (non-significant)  reflect differences in latent variable complexity.

Observations

CD_score: Mean = 3.993, Median = 4.125, SD = 0.78, with high scores on cd_speed_convenience (Mean = 4.106) and cd_strategy_influence (Mean = 4.064), reflecting strong customer demand for digital services.

Strong correlations with DT (r = 0.74) and BMA (r = 0.71) support CD’s role in the DT-BMA relationship.

Benefits: Customer experience (25.1%) and data-driven insights (17.0%) align with CD items like cd_personalization (Mean = 3.979) and cd_behavior_analysis (Mean = 3.962).

Recommendations: Scalability (4.3%) and user-friendly tools (implied in open-ended responses) support CD-driven innovations like omnichannel demand (Mean = 3.966).

Implications:Firms should leverage CD to amplify DT’s impact on BMA, focusing on personalized and omnichannel services.

- Conclusion for RQ3:


Customer demand significantly mediates the relationship between digital transformation and business model alignment (Indirect effect = 0.113, p = 0.001). The mediated effect accounts for 13.7% of the total effect. H3 is supported, with DT enhancing CD (β = 0.70), which partially drives BMA (β = 0.16). This confirms that customer expectations for digital services are a key mechanism in the DT-BMA relationship.





#  Integrated Structural Equation Modeling (SEM)

Purpose: SEM integrates the direct effect (RQ1), moderation (RQ2), and mediation (RQ3) into a single model, accounting for measurement error and providing a comprehensive test of the theoretical framework.



## Integrated Full Model

```{r}
# Fit full model
model4 <- lm(BMA_score ~ DT_centered + FH_centered + CD_centered + 
               DT_centered:FH_centered + DT_centered:CD_centered, 
             data = digital_df)
model4_summary <- summary(model4)

# Extract results cleanly
p_stars <- function(p) {
  ifelse(p < 0.001, "***",
         ifelse(p < 0.01, "**",
                ifelse(p < 0.05, "*", "ns")))
}

model4_results <- data.frame(
  Variable = c("(Intercept)", "Digital Transformation", "Financial Health", 
               "Customer Demand", "DT × FH Interaction", "DT × CD Interaction"),
  Beta = round(coef(model4), 3),
  SE = round(model4_summary$coefficients[,2], 3),
  t_value = round(model4_summary$coefficients[,3], 3),
  P_value = round(model4_summary$coefficients[,4], 4),
  CI_Lower = round(confint(model4)[,1], 3),
  CI_Upper = round(confint(model4)[,2], 3),
  Significance = p_stars(model4_summary$coefficients[,4])
)

kk(model4_results, "Full Integrated Model: Moderation and Mediation Effects")



# Define required models
model1 <- lm(BMA_score ~ DT_score, data = digital_df)        # Direct effect
model2 <- lm(BMA_score ~ DT_score + FH_score + DT_score:FH_score, data = digital_df)  # Moderation
model3b <- lm(BMA_score ~ DT_score + CD_score, data = digital_df)  # Mediation

# Comparison table
model_comparison <- data.frame(
  Model = c("Model 1: Direct Effect", "Model 2: Moderation", 
            "Model 3b: Mediation", "Model 4: Full Integrated"),
  Predictors = c("DT", "DT + FH + DT×FH", "DT + CD", "DT + FH + CD + DT×FH + DT×CD"),
  R_squared = round(c(summary(model1)$r.squared,
                      summary(model2)$r.squared,
                      summary(model3b)$r.squared,
                      summary(model4)$r.squared), 3),
  Adj_R_squared = round(c(summary(model1)$adj.r.squared,
                          summary(model2)$adj.r.squared,
                          summary(model3b)$adj.r.squared,
                          summary(model4)$adj.r.squared), 3),
  F_statistic = round(c(summary(model1)$fstatistic[1],
                        summary(model2)$fstatistic[1],
                        summary(model3b)$fstatistic[1],
                        summary(model4)$fstatistic[1]), 3),
  AIC = round(c(AIC(model1), AIC(model2), AIC(model3b), AIC(model4)), 1),
  BIC = round(c(BIC(model1), BIC(model2), BIC(model3b), BIC(model4)), 1),
  Delta_AIC = round(c(0, AIC(model2) - AIC(model1),
                      AIC(model3b) - AIC(model1),
                      AIC(model4) - AIC(model1)), 1)
)

kk(model_comparison, "Comprehensive Model Comparison Summary")




# Cohen's f² for each predictor: f² = R²_increment / (1 - R²_full)
# Here, approximate by dividing full R² by number of predictors (simplified)
num_predictors <- 5  # exclude intercept
f2_values <- (summary(model4)$r.squared / (1 - summary(model4)$r.squared)) / num_predictors

effect_sizes <- data.frame(
  Variable = c("Digital Transformation", "Financial Health", "Customer Demand", 
               "DT × FH Interaction", "DT × CD Interaction"),
  Beta = round(coef(model4)[2:6], 3),
  Cohen_f2 = round(f2_values, 3),
  Effect_Size_Interpretation = case_when(
    abs(coef(model4)[2:6]) < 0.1 ~ "Small",
    abs(coef(model4)[2:6]) < 0.3 ~ "Medium",
    abs(coef(model4)[2:6]) < 0.5 ~ "Large",
    TRUE ~ "Very Large"
  )
)

kk(effect_sizes, "Effect Size Interpretation for Full Model")

```


Full Integrated Model (Model 4)

Coefficients:

DT_centered (β = 0.51, p < 0.001), FH_centered (β = 0.44, p < 0.001), CD_centered (β = 0.07, p = 0.18), DT × FH (β = -0.19, p = 0.02), DT × CD (β = 0.10, p = 0.06).

Fit: R² = 0.78, F(5,228) = 165.54, p < 0.001, AIC = 208.4.

Robust SEs: DT × FH (p = 0.01), DT × CD (p = 0.12).

Effect Sizes: DT (Very Large), FH (Large), CD (Small), DT × FH (Medium).

Model Comparison:Model 1 (Direct): R² = 0.74, AIC = 247.0.

Model 2 (Moderation): R² = 0.78, AIC = 208.8, ΔAIC = -38.2.

Model 3b (Mediation): R² = 0.75, AIC = 238.7, ΔAIC = -8.3.

Model 4 (Full): R² = 0.78, AIC = 208.4, ΔAIC = -38.6 (best fit).

SEM Results:Paths: DT → CD (β = 0.82, p < 0.001), DT → BMA (β = 0.73, p = 0.03), FH → BMA (β = 0.50, p = 0.04), CD → BMA (β = -0.13, p = 0.22), DT × FH (β = -0.01, p = 0.80), Indirect (β = -0.11, p = 0.23).

Fit: Chi-square = 1608.725 (p < 0.001), CFI = 0.774 (poor), RMSEA = 0.119 (poor).

Interpretation: Model 4 offers the best fit, confirming DT and FH as key predictors with significant moderation (DT × FH), but SEM's poor fit suggests misspecification.Implications: The full model highlights synergies between DT, FH, and CD, but poor SEM fit calls for refinement




#  Visualizations


```{r}
library(ggplot2)
library(viridis)

ggplot(digital_df, aes(x = DT_score, y = BMA_score)) +
  geom_point(aes(color = FH_score), alpha = 0.6, size = 2) +
  geom_smooth(method = "lm", se = TRUE, color = "red", linewidth = 1.2) +
  scale_color_viridis_c(option = "plasma", name = "Financial\nHealth") +
  labs(title = "Digital Transformation → Business Model Alignment",
       subtitle = paste0("R² = ", round(summary(model1)$r.squared, 3), 
                         ", β = ", round(coef(model1)[2], 3)),
       x = "Digital Transformation Score", 
       y = "Business Model Alignment Score") +
  theme(legend.position = "right")



digital_df$FH_group <- ifelse(digital_df$FH_score > median(digital_df$FH_score, na.rm = TRUE), 
                              "High Financial Health", "Low Financial Health")

ggplot(digital_df, aes(x = DT_score, y = BMA_score, color = FH_group)) +
  geom_point(alpha = 0.6, size = 2) +
  geom_smooth(method = "lm", se = TRUE, linewidth = 1.2) +
  scale_color_viridis_d(option = "plasma", begin = 0.2, end = 0.8, name = "Financial Health") +
  labs(title = "Moderation Effect of Financial Health",
       subtitle = "Digital Transformation × Financial Health Interaction",
       x = "Digital Transformation Score", 
       y = "Business Model Alignment Score") +
  theme(legend.position = "bottom")




library(DiagrammeR)
library(glue)

mediation_diagram <- grViz(glue("
digraph mediation {{
  graph [layout = dot, rankdir = LR]
  
  node [shape = rectangle, style = filled, fillcolor = lightblue, fontname = Arial]
  DT [label = 'Digital\\nTransformation']
  CD [label = 'Customer\\nDemand']
  BMA [label = 'Business Model\\nAlignment']
  
  edge [fontname = Arial, fontsize = 10]
  DT -> CD [label = 'a = {round(a_path, 3)}']
  CD -> BMA [label = 'b = {round(b_path, 3)}']
  DT -> BMA [label = 'c\\' = {round(c_prime_path, 3)}', style = dashed]
}}
"))
mediation_diagram






library(dplyr)

residual_data <- digital_df %>%
  filter(!is.na(BMA_score), !is.na(DT_score), !is.na(FH_score), !is.na(CD_score)) %>%
  mutate(
    fitted_full = fitted(model4),
    standardized_residuals = rstandard(model4)
  )

ggplot(residual_data, aes(x = fitted_full, y = standardized_residuals)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  geom_smooth(method = "loess", se = TRUE, color = "orange") +
  labs(title = "Residual Plot: Full Integrated Model",
       x = "Fitted Values", y = "Standardized Residuals")

```



```{r advanced_plots}
# 1. Effect size visualization
effect_plot_data <- data.frame(
  Effect = c("Direct Effect", "Moderation", "Mediation (Indirect)", "Full Model R²"),
  Value = c(coef(model1)[2], coef(model2)[4], indirect_effect, summary(model4)$r.squared),
  Type = c("Main", "Interaction", "Indirect", "Explained Variance"),
  Significance = c(
    ifelse(summary(model1)$coefficients[2,4] < 0.05, "Significant", "Non-significant"),
    ifelse(summary(model2)$coefficients[4,4] < 0.05, "Significant", "Non-significant"),
    ifelse(sobel_p < 0.05, "Significant", "Non-significant"),
    "Model Fit"
  )
)

ggplot(effect_plot_data[1:3,], aes(x = Effect, y = Value, fill = Significance)) +
  geom_col(alpha = 0.8, width = 0.6) +
  geom_text(aes(label = round(Value, 3)), vjust = -0.5, fontface = "bold") +
  scale_fill_manual(values = c("Significant" = "#E46726", "Non-significant" = "#6D9EC1")) +
  labs(title = "Effect Sizes Across Research Questions",
       x = "Type of Effect", y = "Coefficient Value") +
  theme(legend.position = "bottom")

# 2. R-squared comparison
r2_data <- data.frame(
  Model = c("Direct Effect", "Moderation", "Mediation", "Full Model"),
  R_squared = c(summary(model1)$r.squared, summary(model2)$r.squared,
                summary(model3b)$r.squared, summary(model4)$r.squared),
  Adj_R_squared = c(summary(model1)$adj.r.squared, summary(model2)$adj.r.squared,
                    summary(model3b)$adj.r.squared, summary(model4)$adj.r.squared)
) %>%
  gather(key = "Metric", value = "Value", -Model) %>%
  mutate(Model = factor(Model, levels = c("Direct Effect", "Moderation", "Mediation", "Full Model")))

ggplot(r2_data, aes(x = Model, y = Value, fill = Metric)) +
  geom_col(position = "dodge", alpha = 0.8) +
  geom_text(aes(label = round(Value, 3)), position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3, fontface = "bold") +
  scale_fill_brewer(type = "qual", palette = "Set2") +
  labs(title = "Model Fit Comparison",
       subtitle = "R-squared and Adjusted R-squared values",
       x = "Model Type", y = "R-squared Value") 
```

# Structural Equation Modeling (SEM)



```{r}
library(lavaan)
library(dplyr)

# --- Step 1: Create interaction term in dataset ---
digital_df <- digital_df %>%
  mutate(DT_FH = DT_score * FH_score)  # Manifest interaction

# --- Step 2: Define SEM model ---
sem_model <- '
  # Measurement models
  DT =~ dt_leadership_support + dt_investment_consistency + dt_process_integration + 
        dt_staff_training + dt_automation_productivity + dt_analytical_tools + dt_it_infrastructure
  
  BMA =~ bma_digital_revenue + bma_digital_channels + bma_customer_satisfaction + 
         bma_platform_models + bma_feedback_loops + bma_collaboration + bma_competitive_advantage
  
  FH =~ fh_project_capability + fh_roi_tracking + fh_liquidity_ratios + 
        fh_constraints_delay_rev + fh_longterm_evaluation + fh_cost_reduction
  
  CD =~ cd_response_speed + cd_platform_preference + cd_personalization + 
        cd_behavior_analysis + cd_strategy_influence + cd_omnichannel_demand + 
        cd_speed_convenience + cd_adoption_improvement
  
  # Structural model
  CD ~ a*DT
  BMA ~ c_prime*DT + b*CD + d*FH + e*DT_FH
  
  # Indirect effects
  indirect := a*b
  total := c_prime + indirect
'

# --- Step 3: Fit SEM model ---
sem_fit <- sem(sem_model, data = digital_df, estimator = "MLR")

# --- Step 4: Extract fit indices ---
fit_indices <- fitMeasures(sem_fit, c("chisq","df","pvalue","cfi","tli",
                                      "rmsea","rmsea.ci.lower","rmsea.ci.upper",
                                      "srmr","aic","bic"))

sem_fit_table <- data.frame(
  Fit_Index = c("Chi-square", "df", "p-value", "CFI", "TLI", "RMSEA", 
                "RMSEA CI Lower", "RMSEA CI Upper", "SRMR", "AIC", "BIC"),
  Value = round(fit_indices, 3)
)

kk(sem_fit_table, "SEM Fit Indices")

# --- Step 5: Parameter estimates ---
sem_params <- parameterEstimates(sem_fit, standardized = TRUE) %>%
  filter(op %in% c("~", ":=")) %>%
  select(lhs, op, rhs, est, se, z, pvalue, std.all) %>%
  mutate(
    est = round(est, 3),
    se = round(se, 3),
    z = round(z, 3),
    pvalue = round(pvalue, 4),
    std.all = round(std.all, 3),
    significance = case_when(
      pvalue < 0.001 ~ "***",
      pvalue < 0.01 ~ "**",
      pvalue < 0.05 ~ "*",
      TRUE ~ "ns"
    )
  )

kk(sem_params, "SEM Parameter Estimates")

# --- Step 6: Top 10 modification indices ---
mod_indices <- modificationIndices(sem_fit) %>%
  arrange(desc(mi)) %>%
  head(10) %>%
  mutate(
    mi = round(mi, 3),
    epc = round(epc, 3),
    sepc.lv = round(sepc.lv, 3),
    sepc.all = round(sepc.all, 3)
  )

kk(mod_indices, "Top 10 Modification Indices")

```


# Other robustness checks 

```{r}
library(dplyr)
library(lmtest)
library(sandwich)

set.seed(123)

# Number of complete cases
n_complete <- sum(complete.cases(digital_df[, c("DT_score", "BMA_score", "FH_score", "CD_score")]))

# Bootstrap iterations
bootstrap_results <- replicate(1000, {
  boot_sample <- digital_df %>%
    filter(complete.cases(.)) %>%
    slice_sample(n = n_complete, replace = TRUE)
  
  # Fit models
  m1 <- lm(BMA_score ~ DT_score, data = boot_sample)
  m2 <- lm(BMA_score ~ DT_centered * FH_centered, data = boot_sample)  # * includes interaction
  m3a <- lm(CD_score ~ DT_score, data = boot_sample)
  m3b <- lm(BMA_score ~ DT_score + CD_score, data = boot_sample)
  
  # Extract coefficients safely
  c(
    direct_effect = coef(m1)["DT_score"] %||% NA,
    moderation   = coef(m2)["DT_centered:FH_centered"] %||% NA,
    indirect_effect = if("DT_score" %in% names(coef(m3a)) & "CD_score" %in% names(coef(m3b))) {
      coef(m3a)["DT_score"] * coef(m3b)["CD_score"]
    } else NA
  )
})

# Remove columns with all NAs
bootstrap_results <- bootstrap_results[, colSums(is.na(bootstrap_results)) < nrow(bootstrap_results)]

# Compute bootstrap confidence intervals
bootstrap_ci <- apply(bootstrap_results, 1, quantile, c(0.025, 0.975), na.rm = TRUE)

# Original estimates safely
orig_direct <- coef(model1)["DT_score"] %||% NA
orig_moderation <- coef(model2)["DT_centered:FH_centered"] %||% NA
orig_indirect <- indirect_effect %||% NA

# Bootstrap summary table
bootstrap_summary <- data.frame(
  Parameter = c("Direct Effect", "Moderation Effect", "Indirect Effect"),
  Original_Estimate = c(orig_direct, orig_moderation, orig_indirect),
  Bootstrap_Mean = apply(bootstrap_results, 1, mean, na.rm = TRUE),
  Bootstrap_SE = apply(bootstrap_results, 1, sd, na.rm = TRUE),
  CI_Lower_2.5 = bootstrap_ci[1, ],
  CI_Upper_97.5 = bootstrap_ci[2, ],
  Bias = apply(bootstrap_results, 1, mean, na.rm = TRUE) -
         c(orig_direct, orig_moderation, orig_indirect)
) %>%
  mutate(across(where(is.numeric), ~round(.x, 4)))

kk(bootstrap_summary, "Bootstrap Robustness Analysis (1000 iterations)")



# --- 2. Influential observations ---
influence_data <- digital_df %>%
  filter(complete.cases(select(., DT_score, BMA_score, FH_score, CD_score))) %>%
  mutate(
    leverage = hatvalues(model4),
    cooks_d = cooks.distance(model4),
    dfbetas_dt = dfbetas(model4)[, "DT_centered"],
    standardized_residuals = rstandard(model4),
    high_leverage = leverage > 2 * length(coef(model4)) / nrow(.),
    high_cooks = cooks_d > 4 / nrow(.),
    outlier = abs(standardized_residuals) > 2
  )

influential_summary <- influence_data %>%
  summarise(
    N_High_Leverage = sum(high_leverage),
    N_High_Cooks = sum(high_cooks),
    N_Outliers = sum(outlier),
    Max_Cooks_D = round(max(cooks_d), 4),
    Max_Leverage = round(max(leverage), 4)
  )

kk(influential_summary, "Influential Observations Analysis")

# --- 3. Robust standard errors ---
robust_model4 <- coeftest(model4, vcov = vcovHC(model4, type = "HC3"))

robust_comparison <- data.frame(
  Variable = names(coef(model4)),
  OLS_Beta = round(coef(model4), 3),
  OLS_SE = round(summary(model4)$coefficients[,2], 3),
  Robust_SE = round(robust_model4[,2], 3),
  Robust_t = round(robust_model4[,3], 3),
  Robust_p = round(robust_model4[,4], 4),
  SE_Change = round(robust_model4[,2] - summary(model4)$coefficients[,2], 3)
)

kk(robust_comparison, "Robust Standard Errors Comparison")

```

Bootstrap: Direct (CI [0.77, 0.89]), Indirect (CI [0.03, 0.22]) 

effects robust; moderation CI includes zero.

Influential Observations: 28 high-leverage, 20 high Cook’s D, 12 outliers; moderate impact.

Robust SEs: Confirm Model 4's DT × FH significance.

Interpretation: Results are stable, with minimal bias.

Implications: Supports reliability of findings.

Observations: Influential points exist but do not undermine key effects.



# Qualitative Analysis of Open-Ended Responses


```{r}
library(dplyr)
library(tm)
library(quanteda)
library(tidytext)
library(ggplot2)
library(wordcloud2)
library(igraph)
library(ggraph)
library(kableExtra)

set.seed(123)

# --- 1. Data preparation ---
open_ended <- digital_df %>%
  select(benefits_top3, challenges_key, recommendations) %>%
  mutate(across(everything(), ~ gsub("[[:punct:]]|\\n", " ", .)),
         across(everything(), ~ ifelse(tolower(.) %in% c("na", "yes", "no benefits", "none"), NA, .)))



preprocess_text <- function(text) {
  # Ensure text is character and replace NA with empty string
  text <- as.character(text)
  text[is.na(text)] <- ""
  
  # Process each element separately
  sapply(text, function(t) {
    t <- tolower(t)
    t <- gsub("[[:punct:]]|\\n", " ", t)
    t <- gsub("[0-9]", "", t)
    t <- gsub("\\s+", " ", t)      # Remove extra whitespace
    t <- trimws(t)
    # Remove stopwords
    t_tokens <- unlist(strsplit(t, " "))
    t_tokens <- t_tokens[!t_tokens %in% stopwords("english")]
    paste(t_tokens, collapse = " ")
  }, USE.NAMES = FALSE)
}


open_ended <- open_ended %>%
  mutate(across(everything(), ~ preprocess_text(.)))


# --- 4. Term frequency function (keeps Top 20 per variable) ---
term_freq <- function(text, var_name) {
  dfm_obj <- text %>%
    corpus() %>%
    tokens() %>%
    dfm() %>%
    dfm_remove(stopwords("english")) %>%
    dfm_trim(min_termfreq = 2)
  
  freq <- colSums(dfm_obj)
  freq <- sort(freq, decreasing = TRUE)[1:20]
  data.frame(
    Term = names(freq),
    Frequency = as.integer(freq),
    stringsAsFactors = FALSE
  ) %>%
    rename(!!paste0(var_name, "_Term") := Term,
           !!paste0(var_name, "_Frequency") := Frequency)
}

# Get top 20 separately
benefits_freq <- term_freq(open_ended$benefits_top3[!is.na(open_ended$benefits_top3)], "Benefits")
challenges_freq <- term_freq(open_ended$challenges_key[!is.na(open_ended$challenges_key)], "Challenges")
recommendations_freq <- term_freq(open_ended$recommendations[!is.na(open_ended$recommendations)], "Recommendations")

# Combine side by side
term_freq_table <- bind_cols(
  benefits_freq,
  challenges_freq,
  recommendations_freq
)

# Display nicely
kk(term_freq_table, "Top 20 Terms by Frequency (Side by Side)")




# --- 5. Theme coding ---
themes <- list(
  Benefits = list(
    Efficiency = c("efficiency", "productivity", "streamlined", "automation", "faster"),
    Customer_Experience = c("customer", "experience", "service", "personalized", "engagement"),
    Data_Driven = c("data", "analytics", "decision", "insights", "real"),
    Innovation = c("innovation", "agility", "scalable", "modern", "new"),
    Communication = c("communication", "collaboration", "connectivity")
  ),
  Challenges = list(
    Resistance_Change = c("resistance", "change", "reluctance", "adopt"),
    Financial_Costs = c("cost", "financial", "budget", "investment"),
    Digital_Skills = c("skills", "training", "literacy", "expertise"),
    Data_Security = c("security", "privacy", "cybersecurity", "compliance"),
    Infrastructure = c("infrastructure", "legacy", "connectivity", "integration")
  ),
  Recommendations = list(
    Training = c("training", "skills", "education", "literacy"),
    Strategy = c("strategy", "roadmap", "vision", "plan"),
    Cybersecurity = c("security", "cybersecurity", "compliance", "governance"),
    Scalability = c("scalable", "cloud", "flexible", "integration"),
    Change_Management = c("change", "culture", "leadership", "buy")
  )
)

# Assign themes to each text response
assign_themes <- function(text, theme_list) {
  sapply(names(theme_list), function(theme) {
    any(sapply(theme_list[[theme]], function(word) grepl(word, text, ignore.case = TRUE)))
  }) %>% as.data.frame()
}

open_ended <- open_ended %>%
  mutate(
    Benefits_Themes = I(lapply(benefits_top3, assign_themes, themes$Benefits)),
    Challenges_Themes = I(lapply(challenges_key, assign_themes, themes$Challenges)),
    Recommendations_Themes = I(lapply(recommendations, assign_themes, themes$Recommendations))
  )



# For each theme set, calculate frequency of theme occurrence
benefits_theme_freq <- sapply(names(themes$Benefits), function(theme) {
  sum(grepl(paste(themes$Benefits[[theme]], collapse = "|"), open_ended$benefits_top3, ignore.case = TRUE), na.rm = TRUE)
})

challenges_theme_freq <- sapply(names(themes$Challenges), function(theme) {
  sum(grepl(paste(themes$Challenges[[theme]], collapse = "|"), open_ended$challenges_key, ignore.case = TRUE), na.rm = TRUE)
})

recommendations_theme_freq <- sapply(names(themes$Recommendations), function(theme) {
  sum(grepl(paste(themes$Recommendations[[theme]], collapse = "|"), open_ended$recommendations, ignore.case = TRUE), na.rm = TRUE)
})

# Combine into summary table
theme_summary <- data.frame(
  Theme = c(names(benefits_theme_freq), names(challenges_theme_freq), names(recommendations_theme_freq)),
  Frequency = c(benefits_theme_freq, challenges_theme_freq, recommendations_theme_freq)
) %>%
  mutate(Percentage = round(Frequency / nrow(open_ended) * 100, 1))

kk(theme_summary, "Theme Frequencies Across Open-Ended Variables")




# --- 7. Visualizations ---
# Word clouds
wordcloud2(benefits_freq, size = 0.5, shape = "circle", color = "random-dark", backgroundColor = "white")
wordcloud2(challenges_freq, size = 0.5, shape = "circle", color = "random-dark", backgroundColor = "white")
wordcloud2(recommendations_freq, size = 0.5, shape = "circle", color = "random-dark", backgroundColor = "white")

# Bar plot of theme frequencies
ggplot(theme_summary, aes(x = reorder(Theme, Percentage), y = Percentage, fill = Theme)) +
  geom_col(alpha = 0.8) +
  geom_text(aes(label = paste0(Percentage, "%")), vjust = -0.5, fontface = "bold") +
  labs(title = "Theme Frequencies for Open-Ended Responses", x = "Theme", y = "Percentage of Responses") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "none")




# --- 9. Link themes to quantitative variables ---
theme_quant_link <- open_ended %>%
  transmute(
    Benefits_Present = sapply(Benefits_Themes, function(x) any(unlist(x))),
    Challenges_Present = sapply(Challenges_Themes, function(x) any(unlist(x))),
    Recommendations_Present = sapply(Recommendations_Themes, function(x) any(unlist(x)))
  ) %>%
  bind_cols(digital_df %>% select(DT_score, BMA_score, FH_score, CD_score)) %>%
  summarise(across(where(is.numeric), list(mean = ~mean(., na.rm = TRUE), sd = ~sd(., na.rm = TRUE))))

kk(theme_quant_link, "Mean Scores of Quantitative Variables by Theme Presence")

```

Top Terms: Benefits (improved: 42, customer: 37), Challenges (digital: 46, data: 24), Recommendations (digital: 49, training: 35).


Themes:Benefits: Customer Experience (25.1%), Efficiency (22.6%).

Challenges: Financial Costs (13.2%), Resistance to Change (11.1%).

Recommendations: Training (17.4%), Strategy (6.4%).

Quantitative Link: Means consistent across themes (DT: 3.83, BMA: 3.85).

Interpretation: Themes align with quantitative results, emphasizing customer-driven DT and financial barriers.

Implications: Training and strategy can mitigate challenges.

Observations: Themes reinforce DT's role in efficiency and customer experience.




# Hypothesis Testing Summary

```{r}

hypothesis_results <- data.frame(
  Research_Question = c(
    "RQ1: Digital transformation → Business model alignment",
    "RQ2: Financial health moderates DT → BM relationship", 
    "RQ3: Customer demand mediates DT → BM relationship"
  ),
  Hypothesis = c(
    "H1: Digital transformation positively affects business model alignment",
    "H2: Financial health moderates the DT-BMA relationship",
    "H3: Customer demand mediates the DT-BMA relationship"
  ),
  Statistical_Test = c(
    "Simple Linear Regression",
    "Moderated Multiple Regression",
    "Mediation Analysis (Baron & Kenny + Sobel Test)"
  ),
  Key_Statistic = c(
    paste0("β = ", round(coef(model1)["DT_score"], 3), 
           ", t = ", round(summary(model1)$coefficients["DT_score", "t value"], 3)),
    paste0("β = ", round(coef(model2)["DT_score:FH_score"], 3), 
           ", t = ", round(summary(model2)$coefficients["DT_score:FH_score", "t value"], 3)),
    paste0("Indirect effect = ", round(indirect_effect, 3), 
           ", Sobel Z = ", round(sobel_z, 3))
  ),
  P_Value = c(
    round(summary(model1)$coefficients["DT_score", "Pr(>|t|)"], 4),
    round(summary(model2)$coefficients["DT_score:FH_score", "Pr(>|t|)"], 4),
    round(sobel_p, 4)
  ),
  Effect_Size = c(
    paste0("R² = ", round(summary(model1)$r.squared, 3)),
    paste0("ΔR² = ", round(summary(model2)$r.squared - summary(model1)$r.squared, 3)),
    paste0("Proportion mediated = ", round(abs(mediation_ratio), 3))
  ),
  Decision = c(
    ifelse(summary(model1)$coefficients["DT_score", "Pr(>|t|)"] < 0.05, "SUPPORTED", "NOT SUPPORTED"),
    ifelse(summary(model2)$coefficients["DT_score:FH_score", "Pr(>|t|)"] < 0.05, "SUPPORTED", "NOT SUPPORTED"),
    ifelse(sobel_p < 0.05, "SUPPORTED", "NOT SUPPORTED")
  ),
  Practical_Significance = c(
    case_when(
      abs(coef(model1)["DT_score"]) < 0.1 ~ "Small practical effect",
      abs(coef(model1)["DT_score"]) < 0.3 ~ "Moderate practical effect", 
      TRUE ~ "Large practical effect"
    ),
    case_when(
      abs(coef(model2)["DT_score:FH_score"]) < 0.1 ~ "Small interaction effect",
      abs(coef(model2)["DT_score:FH_score"]) < 0.3 ~ "Moderate interaction effect",
      TRUE ~ "Large interaction effect" 
    ),
    case_when(
      abs(mediation_ratio) < 0.2 ~ "Weak mediation",
      abs(mediation_ratio) < 0.5 ~ "Moderate mediation",
      TRUE ~ "Strong mediation"
    )
  )
)



kk(hypothesis_results, "Hypothesis Testing Results Summary")

```






#  Conclusion 

This  thesis has  explored the interplay between digital transformation (DT), business model alignment (BMA), financial health (FH), and customer demand (CD) in service-based firms. Through a mixed-methods approach—combining survey data from 235 respondents, statistical analyses (regression, moderation, mediation, ANOVA, SEM), and qualitative thematic coding—the study provides robust evidence aligned with its objectives and research questions.For RQ1, the findings affirm that DT significantly and positively impacts service business models (β = 0.82, p < 0.001, R² = 0.736), strongly supporting H1. DT initiatives, such as automation, analytical tools, and IT infrastructure, drive BMA through innovations like digital revenue streams, platform-based models, and enhanced customer satisfaction. This relationship is particularly pronounced in consulting/professional services firms (BMA Mean = 4.05), where technology-intensive operations facilitate stronger alignment, compared to hospitality (Mean = 3.55). Qualitative responses reinforce this, emphasizing benefits like improved efficiency (22.6%), better customer experience (25.1%), and data-driven decision-making (17.0%), which align with high-scoring BMA items.

RQ2 reveals a nuanced moderating role for FH in the DT-BMA relationship, with mixed support for H2. While FH exerts a strong direct effect on BMA (β = 0.44, p < 0.001), the interaction term is non-significant in the base moderation model (β = -0.07, p = 0.10) and SEM (p = 0.80), but significant in the full integrated model (β = -0.19, p = 0.02). Simple slopes indicate DT's positive effect persists across FH levels, albeit slightly weaker at high FH, suggesting diminishing returns in financially robust firms. This implies FH enables DT adoption (e.g., through cost reduction and liquidity) but does not substantially alter its impact on BMA. Challenges like financial costs (13.2%) and infrastructure limitations (6.0%) underscore FH's role as a barrier or facilitator.

For RQ3, CD partially mediates the DT-BMA relationship (indirect effect = 0.113, p = 0.001, 13.7% of total effect), supporting H3. DT boosts CD (β = 0.70, p < 0.001), which in turn enhances BMA (β = 0.16, p = 0.001), driven by demands for speed, personalization, and omnichannel experiences. However, SEM shows a non-significant indirect effect (p = 0.23), highlighting methodological nuances. High CD scores (Mean = 3.993) and qualitative themes like customer experience align with this mediation, emphasizing CD as an external catalyst for digital innovation.The integrated model (Model 4) offers the best fit (R² = 0.78, AIC = 208.4), outperforming standalone models, with DT as the dominant predictor (Very Large effect) and FH providing moderate direct and interactive contributions. Robustness checks (bootstrap, influential observations, robust SE) confirm stability, though SEM's poor fit (CFI = 0.774, RMSEA = 0.119) suggests potential misspecification due to construct overlap (e.g., HTMT DT-BMA = 0.95) .
Implications: Service firms should prioritize DT investments, bolstered by FH through ROI tracking and cost reduction, while responding to CD via personalized digital services. Policymakers could support training programs to address skills gaps (9.4% challenge theme) and promote scalable technologies (4.3% recommendation).

